{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T14:29:32.425033Z",
     "iopub.status.busy": "2025-12-28T14:29:32.424824Z",
     "iopub.status.idle": "2025-12-28T14:31:32.827070Z",
     "shell.execute_reply": "2025-12-28T14:31:32.826196Z",
     "shell.execute_reply.started": "2025-12-28T14:29:32.425014Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.4.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 19.0.1\n",
      "    Uninstalling pyarrow-19.0.1:\n",
      "      Successfully uninstalled pyarrow-19.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pyarrow-22.0.0\n",
      "Extracting /kaggle/input/finstructabsa/final_fin_model.zip...\n",
      "‚úÖ Model loaded from: my_trained_model/sentfin_model_large/atsc/googleflan-t5-large-fin_optimized_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-28 14:30:36.515216: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766932236.687581      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1766932236.737576      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for dataset...\n",
      "Reading data from: /kaggle/input/aspect-based-sentiment-analysis-for-financial-news/SEntFiN-v1.1_with_split.csv\n",
      "Filtering for split: test\n",
      "Loaded 3000 examples for evaluation.\n",
      "Running predictions (This may take a few minutes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 94/94 [00:36<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "CLASSIFICATION REPORT (TEST SET)\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive     0.9073    0.9192    0.9132      1065\n",
      "    negative     0.8921    0.9141    0.9030       850\n",
      "     neutral     0.8914    0.8627    0.8768      1085\n",
      "\n",
      "    accuracy                         0.8973      3000\n",
      "   macro avg     0.8969    0.8987    0.8977      3000\n",
      "weighted avg     0.8973    0.8973    0.8972      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Inference & Evaluation on Kaggle Dataset\n",
    "!pip install transformers datasets scikit-learn sentencepiece pandas\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. SETUP MODEL ---\n",
    "zip_path = \"/kaggle/input/finstructabsa/final_fin_model.zip\" # Ensure you uploaded this file!\n",
    "extract_path = \"my_trained_model\"\n",
    "\n",
    "if not os.path.exists(extract_path):\n",
    "    print(f\"Extracting {zip_path}...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "\n",
    "model_dir = None\n",
    "for root, dirs, files in os.walk(extract_path):\n",
    "    if \"config.json\" in files:\n",
    "        model_dir = root\n",
    "        break\n",
    "if model_dir is None: raise ValueError(\"Model not found in zip!\")\n",
    "\n",
    "print(f\"‚úÖ Model loaded from: {model_dir}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- 2. LOAD DATA FROM KAGGLE INPUT (The Modification) ---\n",
    "print(\"Search for dataset...\")\n",
    "dataset_dir = \"/kaggle/input/aspect-based-sentiment-analysis-for-financial-news\"\n",
    "csv_path = None\n",
    "for root, dirs, files in os.walk(dataset_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            csv_path = os.path.join(root, file)\n",
    "            break\n",
    "\n",
    "if not csv_path: raise FileNotFoundError(\"Could not find CSV in /kaggle/input/...\")\n",
    "print(f\"Reading data from: {csv_path}\")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# --- 3. PROCESS DATA (Match Training Logic) ---\n",
    "# We need to extract (Sentence, Aspect, Sentiment) triplets\n",
    "eval_rows = []\n",
    "\n",
    "# Choose 'test' or 'val'. Usually 'test' is for final report.\n",
    "target_split = 'test' \n",
    "print(f\"Filtering for split: {target_split}\")\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # 1. Check Split\n",
    "    if str(row['split']).strip().lower() != target_split:\n",
    "        continue\n",
    "        \n",
    "    # 2. Parse Decisions (e.g., \"{'Stocks': 'Positive'}\")\n",
    "    try:\n",
    "        raw_decisions = row['Decisions']\n",
    "        # Fix common CSV quoting issues\n",
    "        if isinstance(raw_decisions, str):\n",
    "            if '\"\"' in raw_decisions: raw_decisions = raw_decisions.replace('\"\"', '\"')\n",
    "            decisions = ast.literal_eval(raw_decisions)\n",
    "        else:\n",
    "            decisions = raw_decisions\n",
    "            \n",
    "        if not isinstance(decisions, dict): continue\n",
    "\n",
    "        # 3. Create One Row per Aspect (ATSC Task)\n",
    "        for aspect, sentiment in decisions.items():\n",
    "            eval_rows.append({\n",
    "                'raw_text': row['Title'],\n",
    "                'term': aspect,\n",
    "                'labels': sentiment.lower()\n",
    "            })\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "df_eval = pd.DataFrame(eval_rows)\n",
    "print(f\"Loaded {len(df_eval)} examples for evaluation.\")\n",
    "\n",
    "# --- 4. FORMAT PROMPTS (Crucial: Must Match Training) ---\n",
    "# We used InstructABSA-2 (ATSC) format in training\n",
    "# Prompt: Definition + 1 Example + Input\n",
    "prompt_prefix = \"\"\"Definition: The output will be 'positive' if the sentiment of the identified financial entity or aspect in the input is positive (good news, growth, profit). If the sentiment is negative (loss, drop, risk), the answer will be 'negative'. Otherwise, the output should be 'neutral'. For aspects which are classified as noaspectterm, the sentiment is none.\n",
    "Positive example 1- \n",
    "input: Profits for Apple surged by 20% this quarter exceeding expectations. The aspect is Profits. \n",
    "output: positive   \n",
    "Positive example 2-\n",
    "input: The bank maintains a healthy capital adequacy ratio. The aspect is capital adequacy ratio.    \n",
    "output: positive\n",
    "Negative example 1-\n",
    "input: Stocks of Tesla fell sharply due to production delays. The aspect is Stocks.\n",
    "output: negative\n",
    "Negative example 2-\n",
    "input: Rising debt levels are a major concern for the investors. The aspect is debt levels.\n",
    "output: negative\n",
    "Neutral example 1-\n",
    "input: SpiceJet to issue 6.4 crore warrants to promoters. The aspect is SpiceJet.\n",
    "output: neutral\n",
    "Neutral example 2-\n",
    "input: The merger discussion is still ongoing with no final decision. The aspect is merger.\n",
    "output: neutral\n",
    "Now complete the following example-\n",
    "input: \"\"\"\n",
    "\n",
    "\n",
    "inputs = []\n",
    "for _, row in df_eval.iterrows():\n",
    "    # Format: \"input: {text} The aspect is {term}\\noutput:\"\n",
    "    text_input = f\"{prompt_prefix}{row['raw_text']} The aspect is {row['term']}\\noutput:\"\n",
    "    inputs.append(text_input)\n",
    "\n",
    "# --- 5. RUN INFERENCE ---\n",
    "print(\"Running predictions (This may take a few minutes)...\")\n",
    "batch_size = 32\n",
    "predictions = []\n",
    "\n",
    "for i in tqdm(range(0, len(inputs), batch_size)):\n",
    "    batch_texts = inputs[i : i + batch_size]\n",
    "    batch_inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**batch_inputs, max_new_tokens=10)\n",
    "    \n",
    "    batch_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    predictions.extend(batch_preds)\n",
    "\n",
    "# --- 6. FINAL REPORT ---\n",
    "y_true = [str(l).lower().strip() for l in df_eval['labels']]\n",
    "y_pred = [str(p).lower().strip().replace('.','') for p in predictions]\n",
    "# Clean up any hallucinations (rare with T5-Large but possible)\n",
    "valid_labels = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"CLASSIFICATION REPORT ({target_split.upper()} SET)\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_true, y_pred, labels=valid_labels, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T14:47:18.950058Z",
     "iopub.status.busy": "2025-12-28T14:47:18.949351Z",
     "iopub.status.idle": "2025-12-28T14:47:40.139605Z",
     "shell.execute_reply": "2025-12-28T14:47:40.138713Z",
     "shell.execute_reply.started": "2025-12-28T14:47:18.950034Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Attempting to load model from: /kaggle/input/m/joemum/finstructabsa/pytorch/default/1\n",
      "‚úÖ Found config at: /kaggle/input/m/joemum/finstructabsa/pytorch/default/1/sentfin_model_output/atsc/googleflan-t5-base-run1/config.json\n",
      "‚úÖ Success! Model loaded on cuda\n",
      "Loaded 3000 examples.\n",
      "Running predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:10<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       mixed     0.0000    0.0000    0.0000         0\n",
      "    negative     0.8613    0.9353    0.8968       850\n",
      "     neutral     0.9229    0.7945    0.8539      1085\n",
      "    positive     0.8660    0.9286    0.8962      1065\n",
      "\n",
      "    accuracy                         0.8820      3000\n",
      "   macro avg     0.6626    0.6646    0.6617      3000\n",
      "weighted avg     0.8853    0.8820    0.8811      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Cell: Evaluation with Fixed Config for Unrecognized Model\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Config, AutoTokenizer\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. ROBUST MODEL LOADING ---\n",
    "target_model_path = \"/kaggle/input/m/joemum/finstructabsa/pytorch/default/1\"\n",
    "\n",
    "print(f\"üîÑ Attempting to load model from: {target_model_path}\")\n",
    "\n",
    "# Step A: Find the actual config file\n",
    "config_path = None\n",
    "model_root = target_model_path\n",
    "for root, dirs, files in os.walk(target_model_path):\n",
    "    if \"config.json\" in files:\n",
    "        config_path = os.path.join(root, \"config.json\")\n",
    "        model_root = root\n",
    "        break\n",
    "\n",
    "if not config_path:\n",
    "    raise ValueError(\"Could not find config.json in the input path!\")\n",
    "\n",
    "print(f\"‚úÖ Found config at: {config_path}\")\n",
    "\n",
    "# Step B: Load Config & Force 't5' type\n",
    "# We load the JSON manually to inject the missing key\n",
    "with open(config_path, 'r') as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "# FIX: Force the model type if missing\n",
    "if 'model_type' not in config_dict:\n",
    "    print(\"üõ†Ô∏è  Patching config: Adding 'model_type': 't5'\")\n",
    "    config_dict['model_type'] = 't5'\n",
    "    # Also ensure architectures list is correct if missing\n",
    "    if 'architectures' not in config_dict:\n",
    "        config_dict['architectures'] = [\"T5ForConditionalGeneration\"]\n",
    "\n",
    "# Create a config object from the dictionary\n",
    "config = T5Config.from_dict(config_dict)\n",
    "\n",
    "# Step C: Load Model using the specific T5 class and patched config\n",
    "try:\n",
    "    # We use T5ForConditionalGeneration directly instead of AutoModel\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_root, config=config)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_root)\n",
    "    \n",
    "    # Move to GPU\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = model.to(device)\n",
    "    print(f\"‚úÖ Success! Model loaded on {device}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load model: {e}\")\n",
    "    raise e\n",
    "\n",
    "# --- 2. LOAD DATA (Same as before) ---\n",
    "dataset_dir = \"/kaggle/input/aspect-based-sentiment-analysis-for-financial-news\"\n",
    "csv_path = None\n",
    "for root, dirs, files in os.walk(dataset_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            csv_path = os.path.join(root, file)\n",
    "            break\n",
    "if not csv_path: raise FileNotFoundError(\"CSV not found.\")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "eval_rows = []\n",
    "target_split = 'test'\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    if str(row['split']).strip().lower() != target_split: continue\n",
    "    try:\n",
    "        raw_decisions = row['Decisions']\n",
    "        if isinstance(raw_decisions, str):\n",
    "            if '\"\"' in raw_decisions: raw_decisions = raw_decisions.replace('\"\"', '\"')\n",
    "            decisions = ast.literal_eval(raw_decisions)\n",
    "        else:\n",
    "            decisions = raw_decisions\n",
    "        if isinstance(decisions, dict):\n",
    "            for aspect, sentiment in decisions.items():\n",
    "                eval_rows.append({'raw_text': row['Title'], 'term': aspect, 'labels': sentiment.lower()})\n",
    "    except: continue\n",
    "\n",
    "df_eval = pd.DataFrame(eval_rows)\n",
    "print(f\"Loaded {len(df_eval)} examples.\")\n",
    "\n",
    "# --- 3. RUN INFERENCE ---\n",
    "# Use the Standard InstructABSA Prompt\n",
    "prompt_prefix = \"\"\"Definition: The output will be 'positive' if the sentiment of the identified financial entity or aspect in the input is positive (good news, growth, profit). If the sentiment is negative (loss, drop, risk), the answer will be 'negative'. Otherwise, the output should be 'neutral'. For aspects which are classified as noaspectterm, the sentiment is none.\n",
    "Positive example 1- \n",
    "input: Profits for Apple surged by 20% this quarter exceeding expectations. The aspect is Profits. \n",
    "output: positive   \n",
    "Positive example 2-\n",
    "input: The bank maintains a healthy capital adequacy ratio. The aspect is capital adequacy ratio.    \n",
    "output: positive\n",
    "Negative example 1-\n",
    "input: Stocks of Tesla fell sharply due to production delays. The aspect is Stocks.\n",
    "output: negative\n",
    "Negative example 2-\n",
    "input: Rising debt levels are a major concern for the investors. The aspect is debt levels.\n",
    "output: negative\n",
    "Neutral example 1-\n",
    "input: SpiceJet to issue 6.4 crore warrants to promoters. The aspect is SpiceJet.\n",
    "output: neutral\n",
    "Neutral example 2-\n",
    "input: The merger discussion is still ongoing with no final decision. The aspect is merger.\n",
    "output: neutral\n",
    "Now complete the following example-\n",
    "input: \"\"\"\n",
    "\n",
    "\n",
    "inputs = [f\"{prompt_prefix}{row['raw_text']} The aspect is {row['term']}\\noutput:\" for _, row in df_eval.iterrows()]\n",
    "\n",
    "print(\"Running predictions...\")\n",
    "batch_size = 64\n",
    "predictions = []\n",
    "\n",
    "for i in tqdm(range(0, len(inputs), batch_size)):\n",
    "    batch_texts = inputs[i : i + batch_size]\n",
    "    batch_inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**batch_inputs, max_new_tokens=10)\n",
    "    predictions.extend(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "\n",
    "# --- 4. REPORT ---\n",
    "y_true = [str(l).lower().strip() for l in df_eval['labels']]\n",
    "y_pred = [str(p).lower().strip().replace('.','') for p in predictions]\n",
    "print(classification_report(y_true, y_pred, digits=4))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
