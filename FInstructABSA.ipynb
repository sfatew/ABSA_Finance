{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr7HJ-LLXBHz",
        "outputId": "a9979602-dcbc-4d07-999f-cf2746f976b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'instructabsa'...\n",
            "remote: Enumerating objects: 562, done.\u001b[K\n",
            "remote: Counting objects: 100% (224/224), done.\u001b[K\n",
            "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
            "remote: Total 562 (delta 123), reused 197 (delta 106), pack-reused 338 (from 1)\u001b[K\n",
            "Receiving objects: 100% (562/562), 1.58 MiB | 3.16 MiB/s, done.\n",
            "Resolving deltas: 100% (320/320), done.\n",
            "/content/instructabsa\n",
            "Requirement already satisfied: torch>1.8 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.9.0+cpu)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (4.57.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (4.0.0)\n",
            "Collecting evaluate (from -r requirements.txt (line 4))\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>1.8->-r requirements.txt (line 1)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>1.8->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>1.8->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>1.8->-r requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>1.8->-r requirements.txt (line 1)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>1.8->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>1.8->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 3)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 3)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 3)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 2)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 2)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 2)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 2)) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>1.8->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>1.8->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 3)) (1.17.0)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.11.12)\n",
            "Downloading dataset from Kaggle...\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/namdtgk14/aspect-based-sentiment-analysis-for-financial-news?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 361k/361k [00:00<00:00, 973kB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset: /root/.cache/kagglehub/datasets/namdtgk14/aspect-based-sentiment-analysis-for-financial-news/versions/1\n",
            "Found CSV file: /root/.cache/kagglehub/datasets/namdtgk14/aspect-based-sentiment-analysis-for-financial-news/versions/1/SEntFiN-v1.1_with_split.csv\n",
            "Done! Processed data using provided 'split' column.\n",
            " - Created 'train_internal.csv' (7693 rows)\n",
            " - Created 'val_internal.csv' (833 rows)\n",
            " - Created 'test_internal.csv' (2227 rows)\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Setup Environment & Download Data (Updated for namdtgk14 dataset)\n",
        "!git clone https://github.com/kevinscaria/instructabsa.git\n",
        "%cd instructabsa\n",
        "!pip install -r requirements.txt\n",
        "!pip install kagglehub\n",
        "\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "import ast\n",
        "\n",
        "# 1. Download the new dataset\n",
        "print(\"Downloading dataset from Kaggle...\")\n",
        "path = kagglehub.dataset_download(\"namdtgk14/aspect-based-sentiment-analysis-for-financial-news\")\n",
        "print(\"Path to dataset:\", path)\n",
        "\n",
        "# Find the CSV file\n",
        "csv_file = [f for f in os.listdir(path) if f.endswith('.csv')][0]\n",
        "full_path = os.path.join(path, csv_file)\n",
        "print(f\"Found CSV file: {full_path}\")\n",
        "\n",
        "# 2. Process Data using the 'split' column\n",
        "def process_and_split_data(input_path):\n",
        "    df = pd.read_csv(input_path)\n",
        "\n",
        "    formatted_data = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        try:\n",
        "            # Parse 'Decisions' column (String -> Dict)\n",
        "            raw_decisions = row['Decisions']\n",
        "            if isinstance(raw_decisions, str):\n",
        "                # Clean up potential double quotes from CSV parsing issues\n",
        "                if '\"\"' in raw_decisions:\n",
        "                    raw_decisions = raw_decisions.replace('\"\"', '\"')\n",
        "                decisions_dict = ast.literal_eval(raw_decisions)\n",
        "            else:\n",
        "                decisions_dict = raw_decisions\n",
        "\n",
        "            # Convert to list of dicts for InstructABSA\n",
        "            aspect_terms = []\n",
        "            if isinstance(decisions_dict, dict):\n",
        "                for entity, sentiment in decisions_dict.items():\n",
        "                    aspect_terms.append({\n",
        "                        'term': entity,\n",
        "                        'polarity': sentiment.lower()\n",
        "                    })\n",
        "\n",
        "            # Skip rows with no valid aspect terms\n",
        "            if not aspect_terms: continue\n",
        "\n",
        "            # Determine split from the dataset row\n",
        "            # Normalize to lowercase and strip just in case (e.g. \"Train \" -> \"train\")\n",
        "            split_type = str(row['split']).strip().lower()\n",
        "\n",
        "            formatted_data.append({\n",
        "                'sentenceId': f\"{index}:1\",\n",
        "                'raw_text': row['Title'],\n",
        "                'aspectTerms': str(aspect_terms),\n",
        "                'aspectCategories': \"[{'category': 'none', 'polarity': 'none'}]\",\n",
        "                'split_type': split_type  # Keep track of the split\n",
        "            })\n",
        "        except Exception as e:\n",
        "            # print(f\"Skipping row {index}: {e}\") # Optional debugging\n",
        "            continue\n",
        "\n",
        "    # Create DataFrame\n",
        "    final_df = pd.DataFrame(formatted_data)\n",
        "\n",
        "    # 3. Split based on the 'split_type' column\n",
        "    train_df = final_df[final_df['split_type'] == 'train'].drop(columns=['split_type'])\n",
        "    val_df = final_df[final_df['split_type'] == 'val'].drop(columns=['split_type'])\n",
        "    test_df = final_df[final_df['split_type'] == 'test'].drop(columns=['split_type'])\n",
        "\n",
        "    # Save to internal CSVs for the training script\n",
        "    train_df.to_csv('train_internal.csv', index=False)\n",
        "    val_df.to_csv('val_internal.csv', index=False)\n",
        "    test_df.to_csv('test_internal.csv', index=False)\n",
        "\n",
        "    print(f\"Done! Processed data using provided 'split' column.\")\n",
        "    print(f\" - Created 'train_internal.csv' ({len(train_df)} rows)\")\n",
        "    print(f\" - Created 'val_internal.csv' ({len(val_df)} rows)\")\n",
        "    print(f\" - Created 'test_internal.csv' ({len(test_df)} rows)\")\n",
        "\n",
        "process_and_split_data(full_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS9D-lAFXA21",
        "outputId": "1d2038f4-3485-4df9-cc30-9f59776574ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration files created successfully.\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Create Instructions and Data Prep Scripts\n",
        "# 1. instructions.py\n",
        "with open(\"instructions.py\", \"w\") as f:\n",
        "    f.write('''class InstructionsHandler:\n",
        "    def __init__(self):\n",
        "        self.ate = {\n",
        "            'bos_instruct1': \"\"\"Definition: The output will be the financial entities or aspects (both implicit and explicit) which have an associated sentiment/opinion extracted from the input text. In cases where there are no aspects the output should be noaspectterm.\\\\n    Positive example 1-\\\\n    input: Net profit surged by 20% in the last quarter surpassing analyst estimates.\\\\n    output: Net profit\\\\n    Positive example 2-\\\\n    input: The company's balance sheet remains strong with high liquidity.\\\\n    output: balance sheet, liquidity\\\\n    Negative example 1-\\\\n    input: Shares of ABC Corp plummeted due to the scandal.\\\\n    output: Shares\\\\n    Negative example 2-\\\\n    input: High inflation continues to hurt the operating margin.\\\\n    output: operating margin\\\\n    Neutral example 1-\\\\n    input: The board of directors announced a meeting scheduled for next Monday.\\\\n    output: board of directors\\\\n    Neutral example 2-\\\\n    input: SpiceJet to issue 6.4 crore warrants to promoters.\\\\n    output: SpiceJet\\\\n    Now complete the following example-\\\\n    input: \"\"\",\n",
        "            'bos_instruct2': \"\"\"Definition: The output will be the financial entities or aspects (both implicit and explicit) which have an associated sentiment/opinion extracted from the input text. In cases where there are no aspects the output should be noaspectterm.\\\\n    Positive example 1-\\\\n    input: Net profit surged by 20% in the last quarter surpassing analyst estimates.\\\\n    output: Net profit\\\\n    Positive example 2-\\\\n    input: The company's balance sheet remains strong with high liquidity.\\\\n    output: balance sheet, liquidity\\\\n    Negative example 1-\\\\n    input: Shares of ABC Corp plummeted due to the scandal.\\\\n    output: Shares\\\\n    Negative example 2-\\\\n    input: High inflation continues to hurt the operating margin.\\\\n    output: operating margin\\\\n    Neutral example 1-\\\\n    input: The board of directors announced a meeting scheduled for next Monday.\\\\n    output: board of directors\\\\n    Neutral example 2-\\\\n    input: SpiceJet to issue 6.4 crore warrants to promoters.\\\\n    output: SpiceJet\\\\n    Now complete the following example-\\\\n    input: \"\"\",\n",
        "            'eos_instruct': ' \\\\noutput:'\n",
        "        }\n",
        "        self.atsc = {\n",
        "            'bos_instruct1': \"\"\"Definition: The output will be 'positive' if the sentiment of the identified financial entity or aspect in the input is positive (good news, growth, profit). If the sentiment is negative (loss, drop, risk), the answer will be 'negative'. Otherwise, the output should be 'neutral'. For aspects which are classified as noaspectterm, the sentiment is none.\\\\n    Positive example 1-\\\\n    input: Profits for Apple surged by 20% this quarter exceeding expectations. The aspect is Profits.\\\\n    output: positive\\\\n    Positive example 2-\\\\n    input: The bank maintains a healthy capital adequacy ratio. The aspect is capital adequacy ratio.\\\\n    output: positive\\\\n    Negative example 1-\\\\n    input: Stocks of Tesla fell sharply due to production delays. The aspect is Stocks.\\\\n    output: negative\\\\n    Negative example 2-\\\\n    input: Rising debt levels are a major concern for the investors. The aspect is debt levels.\\\\n    output: negative\\\\n    Neutral example 1-\\\\n    input: SpiceJet to issue 6.4 crore warrants to promoters. The aspect is SpiceJet.\\\\n    output: neutral\\\\n    Neutral example 2-\\\\n    input: The merger discussion is still ongoing with no final decision. The aspect is merger.\\\\n    output: neutral\\\\n    Now complete the following example-\\\\n    input: \"\"\",\n",
        "            'bos_instruct2': \"\"\"Definition: The output will be 'positive' if the sentiment of the identified financial entity or aspect in the input is positive (good news, growth, profit). If the sentiment is negative (loss, drop, risk), the answer will be 'negative'. Otherwise, the output should be 'neutral'. For aspects which are classified as noaspectterm, the sentiment is none.\\\\n    Positive example 1-\\\\n    input: Profits for Apple surged by 20% this quarter exceeding expectations. The aspect is Profits.\\\\n    output: positive\\\\n    Positive example 2-\\\\n    input: The bank maintains a healthy capital adequacy ratio. The aspect is capital adequacy ratio.\\\\n    output: positive\\\\n    Negative example 1-\\\\n    input: Stocks of Tesla fell sharply due to production delays. The aspect is Stocks.\\\\n    output: negative\\\\n    Negative example 2-\\\\n    input: Rising debt levels are a major concern for the investors. The aspect is debt levels.\\\\n    output: negative\\\\n    Neutral example 1-\\\\n    input: SpiceJet to issue 6.4 crore warrants to promoters. The aspect is SpiceJet.\\\\n    output: neutral\\\\n    Neutral example 2-\\\\n    input: The merger discussion is still ongoing with no final decision. The aspect is merger.\\\\n    output: neutral\\\\n    Now complete the following example-\\\\n    input: \"\"\",\n",
        "            'delim_instruct': ' The aspect is ',\n",
        "            'eos_instruct': ' \\\\noutput:'\n",
        "        }\n",
        "        self.joint = {\n",
        "            'bos_instruct1': \"\"\"Definition: The output will be the financial aspects and their sentiment polarity. Format: aspect:sentiment.\\\\n    Positive example 1-\\\\n    input: Revenue grew significantly.\\\\n    output: Revenue:positive\\\\n    Negative example 1-\\\\n    input: Costs are spiraling out of control.\\\\n    output: Costs:negative\\\\n    Neutral example 1-\\\\n    input: The CEO spoke at the conference.\\\\n    output: CEO:neutral\\\\n    Now complete the following example-\\\\n    input: \"\"\",\n",
        "            'bos_instruct2': \"\"\"Definition: The output will be the financial aspects and their sentiment polarity. Format: aspect:sentiment.\\\\n    Positive example 1-\\\\n    input: Revenue grew significantly.\\\\n    output: Revenue:positive\\\\n    Negative example 1-\\\\n    input: Costs are spiraling out of control.\\\\n    output: Costs:negative\\\\n    Neutral example 1-\\\\n    input: The CEO spoke at the conference.\\\\n    output: CEO:neutral\\\\n    Now complete the following example-\\\\n    input: \"\"\",\n",
        "            'eos_instruct': ' \\\\noutput:'\n",
        "        }\n",
        "\n",
        "    def load_instruction_set1(self):\n",
        "        self.ate = self.ate\n",
        "        self.atsc = self.atsc\n",
        "        self.joint = self.joint\n",
        "\n",
        "    def load_instruction_set2(self):\n",
        "        self.ate = self.ate\n",
        "        self.atsc = self.atsc\n",
        "        self.joint = self.joint\n",
        "''')\n",
        "\n",
        "# 2. InstructABSA/data_prep.py\n",
        "with open(\"InstructABSA/data_prep.py\", \"w\") as f:\n",
        "    f.write('''from datasets import Dataset\n",
        "from datasets.dataset_dict import DatasetDict\n",
        "import ast\n",
        "\n",
        "class DatasetLoader:\n",
        "    def __init__(self, train_df_id=None, test_df_id=None,\n",
        "                 train_df_ood=None, test_df_ood=None, sample_size=1,\n",
        "                 val_df_id=None, val_df_ood=None):\n",
        "\n",
        "        self.train_df_id = train_df_id.sample(frac=sample_size, random_state=1999) if train_df_id is not None else train_df_id\n",
        "        self.test_df_id = test_df_id\n",
        "        self.train_df_ood = train_df_ood\n",
        "        self.test_df_ood = test_df_ood\n",
        "        self.val_df_id = val_df_id\n",
        "        self.val_df_ood = val_df_ood\n",
        "\n",
        "    def reconstruct_strings(self, df, col):\n",
        "        reconstructed_col = []\n",
        "        for text in df[col]:\n",
        "            try:\n",
        "                if isinstance(text, (list, dict)):\n",
        "                    reconstructed_col.append(text)\n",
        "                elif isinstance(text, str):\n",
        "                    if text == '[]':\n",
        "                        reconstructed_col.append([])\n",
        "                    else:\n",
        "                        reconstructed_col.append(ast.literal_eval(text))\n",
        "                else:\n",
        "                    reconstructed_col.append([])\n",
        "            except (ValueError, SyntaxError):\n",
        "                reconstructed_col.append([])\n",
        "        df[col] = reconstructed_col\n",
        "        return df\n",
        "\n",
        "    def extract_rowwise_aspect_polarity(self, df, on, key, min_val = None):\n",
        "        try:\n",
        "            df.iloc[0][on][0][key]\n",
        "        except:\n",
        "            df = self.reconstruct_strings(df, on)\n",
        "\n",
        "        df['len'] = df[on].apply(lambda x: len(x))\n",
        "        if min_val is not None:\n",
        "            df.loc[df['len'] == 0, 'len'] = min_val\n",
        "        df = df.loc[df.index.repeat(df['len'])]\n",
        "        df['record_idx'] = df.groupby(df.index).cumcount()\n",
        "        df['aspect'] = df[[on, 'record_idx']].apply(lambda x : (x[0][x[1]][key], x[0][x[1]]['polarity']) if len(x[0]) != 0 else ('',''), axis=1)\n",
        "        df['polarity'] = df['aspect'].apply(lambda x: x[-1])\n",
        "        df['aspect'] = df['aspect'].apply(lambda x: x[0])\n",
        "        df = df.drop(['len', 'record_idx'], axis=1).reset_index(drop = True)\n",
        "        return df\n",
        "\n",
        "    def extract_rowwise_aspect_opinions(self, df, aspect_col, opinion_col, key, min_val = None):\n",
        "        df['len'] = df[aspect_col].apply(lambda x: len(x))\n",
        "        if min_val is not None:\n",
        "            df.loc[df['len'] == 0, 'len'] = min_val\n",
        "        df = df.loc[df.index.repeat(df['len'])]\n",
        "        df['record_idx'] = df.groupby(df.index).cumcount()\n",
        "        df['aspect'] = df[[aspect_col, 'record_idx']].apply(lambda x : x[0][x[1]][key] if len(x[0]) != 0 else '', axis=1)\n",
        "        df['opinion_term'] = df[[opinion_col, 'record_idx']].apply(lambda x : x[0][x[1]][key] if len(x[0]) != 0 else '', axis=1)\n",
        "        df['aspect'] = df['aspect'].apply(lambda x: ' '.join(x))\n",
        "        df['opinion_term'] = df['opinion_term'].apply(lambda x: ' '.join(x))\n",
        "        df = df.drop(['len', 'record_idx'], axis=1).reset_index(drop = True)\n",
        "        return df\n",
        "\n",
        "    def create_data_in_ate_format(self, df, key, text_col, aspect_col, bos_instruction = '', eos_instruction = ''):\n",
        "        if df is None: return\n",
        "        try: df.iloc[0][aspect_col][0][key]\n",
        "        except: df = self.reconstruct_strings(df, aspect_col)\n",
        "        df['labels'] = df[aspect_col].apply(lambda x: ', '.join([i[key] for i in x]))\n",
        "        df['text'] = df[text_col].apply(lambda x: bos_instruction + x + eos_instruction)\n",
        "        return df\n",
        "\n",
        "    def create_data_in_atsc_format(self, df, on, key, text_col, aspect_col, bos_instruction = '', delim_instruction = '', eos_instruction = ''):\n",
        "        if df is None: return\n",
        "        df = self.extract_rowwise_aspect_polarity(df, on=on, key=key, min_val=1)\n",
        "        df['text'] = df[[text_col, aspect_col]].apply(lambda x: bos_instruction + x[0] + delim_instruction + x[1] + eos_instruction, axis=1)\n",
        "        df = df.rename(columns = {'polarity': 'labels'})\n",
        "        return df\n",
        "\n",
        "    def create_data_in_aspe_format(self, df, key, label_key, text_col, aspect_col, bos_instruction = '', eos_instruction = ''):\n",
        "        if df is None: return\n",
        "        try: df.iloc[0][aspect_col][0][key]\n",
        "        except: df = self.reconstruct_strings(df, aspect_col)\n",
        "        df['labels'] = df[aspect_col].apply(lambda x: ', '.join([f\"{i[key]}:{i[label_key]}\" for i in x]))\n",
        "        df['text'] = df[text_col].apply(lambda x: bos_instruction + x + eos_instruction)\n",
        "        return df\n",
        "\n",
        "    def create_data_in_aooe_format(self, df, aspect_col, opinion_col, key, text_col, bos_instruction = '', delim_instruction = '', eos_instruction = ''):\n",
        "        if df is None: return\n",
        "        df = self.extract_rowwise_aspect_opinions(df, aspect_col=aspect_col, opinion_col=opinion_col, key=key, min_val=1)\n",
        "        df['text'] = df[[text_col, 'aspect']].apply(lambda x: bos_instruction + x[0] + delim_instruction + x[1] + eos_instruction, axis=1)\n",
        "        df = df.rename(columns = {'opinion_term': 'labels'})\n",
        "        return df\n",
        "\n",
        "    def create_data_in_aope_format(self, df, key, text_col, aspect_col, opinion_col, bos_instruction = '', eos_instruction = ''):\n",
        "        df['labels'] = df[[aspect_col, opinion_col]].apply(lambda x: ', '.join([f\"{' '.join(i[key])}:{' '.join(j[key])}\" for i, j in zip(x[0], x[1])]), axis=1)\n",
        "        df['text'] = df[text_col].apply(lambda x: bos_instruction + x + eos_instruction)\n",
        "        return df\n",
        "\n",
        "    def create_data_in_aoste_format(self, df, key, label_key, text_col, aspect_col, opinion_col, bos_instruction = '', eos_instruction = ''):\n",
        "        label_map = {'POS':'positive', 'NEG':'negative', 'NEU':'neutral'}\n",
        "        df['labels'] = df[[aspect_col, opinion_col]].apply(lambda x: ', '.join([f\"{' '.join(i[key])}:{' '.join(j[key])}:{label_map[i[label_key]]}\" for i, j in zip(x[0], x[1])]), axis=1)\n",
        "        df['text'] = df[text_col].apply(lambda x: bos_instruction + x + eos_instruction)\n",
        "        return df\n",
        "\n",
        "    def set_data_for_training_semeval(self, tokenize_function):\n",
        "        dataset_dict_id, dataset_dict_ood = {}, {}\n",
        "        if self.train_df_id is not None: dataset_dict_id['train'] = Dataset.from_pandas(self.train_df_id)\n",
        "        if self.test_df_id is not None: dataset_dict_id['test'] = Dataset.from_pandas(self.test_df_id)\n",
        "        if self.val_df_id is not None: dataset_dict_id['validation'] = Dataset.from_pandas(self.val_df_id)\n",
        "\n",
        "        if len(dataset_dict_id) > 1:\n",
        "            indomain_dataset = DatasetDict(dataset_dict_id)\n",
        "            indomain_tokenized_datasets = indomain_dataset.map(tokenize_function, batched=True)\n",
        "        else:\n",
        "            indomain_dataset, indomain_tokenized_datasets = {}, {}\n",
        "\n",
        "        if self.train_df_ood is not None: dataset_dict_ood['train'] = Dataset.from_pandas(self.train_df_ood)\n",
        "        if self.test_df_ood is not None: dataset_dict_ood['test'] = Dataset.from_pandas(self.test_df_ood)\n",
        "        if self.val_df_ood is not None: dataset_dict_ood['validation'] = Dataset.from_pandas(self.val_df_ood)\n",
        "\n",
        "        if len(dataset_dict_id) > 1:\n",
        "            other_domain_dataset = DatasetDict(dataset_dict_ood)\n",
        "            other_domain_tokenized_dataset = other_domain_dataset.map(tokenize_function, batched=True)\n",
        "        else:\n",
        "            other_domain_dataset, other_domain_tokenized_dataset = {}, {}\n",
        "\n",
        "        return indomain_dataset, indomain_tokenized_datasets, other_domain_dataset, other_domain_tokenized_dataset\n",
        "''')\n",
        "\n",
        "# 3. InstructABSA/utils.py (Initial version for training)\n",
        "with open(\"InstructABSA/utils.py\", \"w\") as f:\n",
        "    f.write('''import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "from transformers import (\n",
        "    DataCollatorForSeq2Seq, AutoTokenizer, AutoModelForSeq2SeqLM,\n",
        "    Seq2SeqTrainingArguments, Trainer, Seq2SeqTrainer\n",
        ")\n",
        "\n",
        "class T5Generator:\n",
        "    def __init__(self, model_checkpoint):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
        "        self.data_collator = DataCollatorForSeq2Seq(self.tokenizer)\n",
        "        self.device = 'cuda' if torch.has_cuda else ('mps' if torch.has_mps else 'cpu')\n",
        "\n",
        "    def tokenize_function_inputs(self, sample):\n",
        "        model_inputs = self.tokenizer(sample['text'], max_length=512, truncation=True)\n",
        "        labels = self.tokenizer(sample[\"labels\"], max_length=64, truncation=True)\n",
        "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "        return model_inputs\n",
        "\n",
        "    def train(self, tokenized_datasets, **kwargs):\n",
        "        args = Seq2SeqTrainingArguments(**kwargs)\n",
        "        eval_ds = tokenized_datasets.get(\"validation\")\n",
        "        if eval_ds is None: eval_ds = tokenized_datasets.get(\"test\")\n",
        "        trainer = Seq2SeqTrainer(\n",
        "            self.model, args, train_dataset=tokenized_datasets[\"train\"],\n",
        "            eval_dataset=eval_ds, tokenizer=self.tokenizer, data_collator=self.data_collator,\n",
        "        )\n",
        "        torch.cuda.empty_cache()\n",
        "        trainer.train()\n",
        "        trainer.save_model()\n",
        "        return trainer\n",
        "\n",
        "    def get_labels(self, tokenized_dataset, batch_size = 4, max_length = 128, sample_set = 'train'):\n",
        "        def collate_fn(batch):\n",
        "            input_ids = [torch.tensor(example['input_ids']) for example in batch]\n",
        "            input_ids = pad_sequence(input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
        "            return input_ids\n",
        "        dataloader = DataLoader(tokenized_dataset[sample_set], batch_size=batch_size, collate_fn=collate_fn)\n",
        "        predicted_output = []\n",
        "        self.model.to(self.device)\n",
        "        for batch in tqdm(dataloader):\n",
        "            batch = batch.to(self.device)\n",
        "            output_ids = self.model.generate(batch, max_length = max_length)\n",
        "            output_texts = self.tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "            for output_text in output_texts: predicted_output.append(output_text)\n",
        "        return predicted_output\n",
        "\n",
        "    def get_metrics(self, y_true, y_pred, is_triplet_extraction=False):\n",
        "        # Simplified for brevity in this combined script\n",
        "        return precision_score(y_true, y_pred, average='macro'), recall_score(y_true, y_pred, average='macro'), f1_score(y_true, y_pred, average='macro'), None\n",
        "\n",
        "class T5Classifier:\n",
        "    def __init__(self, model_checkpoint):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, force_download = True)\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, force_download = True)\n",
        "        self.data_collator = DataCollatorForSeq2Seq(self.tokenizer)\n",
        "        self.device = 'cuda' if torch.has_cuda else ('mps' if torch.has_mps else 'cpu')\n",
        "\n",
        "    def tokenize_function_inputs(self, sample):\n",
        "        sample['input_ids'] = self.tokenizer(sample[\"text\"], max_length = 512, truncation = True).input_ids\n",
        "        sample['labels'] = self.tokenizer(sample[\"labels\"], max_length = 64, truncation = True).input_ids\n",
        "        return sample\n",
        "\n",
        "    def train(self, tokenized_datasets, **kwargs):\n",
        "        args = Seq2SeqTrainingArguments(**kwargs)\n",
        "        eval_ds = tokenized_datasets.get(\"validation\")\n",
        "        if eval_ds is None: eval_ds = tokenized_datasets.get(\"test\")\n",
        "        trainer = Trainer(\n",
        "            self.model, args, train_dataset=tokenized_datasets[\"train\"],\n",
        "            eval_dataset=eval_ds, tokenizer=self.tokenizer, data_collator = self.data_collator\n",
        "        )\n",
        "        torch.cuda.empty_cache()\n",
        "        trainer.train()\n",
        "        trainer.save_model()\n",
        "        return trainer\n",
        "\n",
        "    def get_labels(self, tokenized_dataset, batch_size = 4, sample_set = 'train'):\n",
        "        def collate_fn(batch):\n",
        "            input_ids = [torch.tensor(example['input_ids']) for example in batch]\n",
        "            input_ids = pad_sequence(input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
        "            return input_ids\n",
        "        dataloader = DataLoader(tokenized_dataset[sample_set], batch_size=batch_size, collate_fn=collate_fn)\n",
        "        predicted_output = []\n",
        "        self.model.to(self.device)\n",
        "        for batch in tqdm(dataloader):\n",
        "            batch = batch.to(self.device)\n",
        "            output_ids = self.model.generate(batch)\n",
        "            output_texts = self.tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "            for output_text in output_texts: predicted_output.append(output_text)\n",
        "        return predicted_output\n",
        "\n",
        "    def get_metrics(self, y_true, y_pred):\n",
        "        return precision_score(y_true, y_pred, average='macro'), recall_score(y_true, y_pred, average='macro'), f1_score(y_true, y_pred, average='macro'), accuracy_score(y_true, y_pred)\n",
        "''')\n",
        "\n",
        "# 4. run_model.py\n",
        "with open(\"run_model.py\", \"w\") as f:\n",
        "    f.write('''import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import torch\n",
        "from InstructABSA.data_prep import DatasetLoader\n",
        "from InstructABSA.utils import T5Generator, T5Classifier\n",
        "from InstructABSA.config import Config\n",
        "from instructions import InstructionsHandler\n",
        "\n",
        "try: use_mps = True if torch.has_mps else False\n",
        "except: use_mps = False\n",
        "\n",
        "config = Config()\n",
        "instruct_handler = InstructionsHandler()\n",
        "if config.inst_type == 1: instruct_handler.load_instruction_set1()\n",
        "else: instruct_handler.load_instruction_set2()\n",
        "\n",
        "if config.mode == 'train' and config.id_tr_data_path is None: raise Exception('Provide training data path.')\n",
        "if config.mode == 'eval' and config.id_te_data_path is None and config.ood_te_data_path is None: raise Exception('Provide testing data path.')\n",
        "\n",
        "if config.experiment_name is not None and config.mode == 'train':\n",
        "    model_checkpoint = config.model_checkpoint\n",
        "    model_out_path = os.path.join(config.output_dir, config.task, f\"{model_checkpoint.replace('/', '')}-{config.experiment_name}\")\n",
        "else:\n",
        "    model_checkpoint = config.model_checkpoint\n",
        "    model_out_path = config.model_checkpoint\n",
        "\n",
        "id_tr_data_path = config.id_tr_data_path\n",
        "ood_tr_data_path = config.ood_tr_data_path\n",
        "id_te_data_path = config.id_te_data_path\n",
        "ood_te_data_path = config.ood_te_data_path\n",
        "\n",
        "if config.mode != 'cli':\n",
        "    id_tr_df, id_te_df, ood_tr_df, ood_te_df = None, None, None, None\n",
        "    if id_tr_data_path: id_tr_df = pd.read_csv(id_tr_data_path)\n",
        "    if id_te_data_path: id_te_df = pd.read_csv(id_te_data_path)\n",
        "    if ood_tr_data_path: ood_tr_df = pd.read_csv(ood_tr_data_path)\n",
        "    if ood_te_data_path: ood_te_df = pd.read_csv(ood_te_data_path)\n",
        "    print('Loaded data...')\n",
        "\n",
        "training_args = {\n",
        "    'output_dir': model_out_path,\n",
        "    'eval_strategy': config.evaluation_strategy if config.id_te_data_path is not None else 'no',\n",
        "    'learning_rate': config.learning_rate,\n",
        "    'per_device_train_batch_size': config.per_device_train_batch_size,\n",
        "    'per_device_eval_batch_size': config.per_device_eval_batch_size,\n",
        "    'num_train_epochs': config.num_train_epochs,\n",
        "    'weight_decay': config.weight_decay,\n",
        "    'warmup_ratio': config.warmup_ratio,\n",
        "    'save_strategy': config.save_strategy,\n",
        "    'load_best_model_at_end': config.load_best_model_at_end,\n",
        "    'push_to_hub': config.push_to_hub,\n",
        "    'eval_accumulation_steps': config.eval_accumulation_steps,\n",
        "    'predict_with_generate': config.predict_with_generate,\n",
        "    'use_mps_device': use_mps\n",
        "}\n",
        "\n",
        "if config.set_instruction_key == 1:\n",
        "    indomain, outdomain = 'bos_instruct1', 'bos_instruct2'\n",
        "else:\n",
        "    indomain, outdomain = 'bos_instruct2', 'bos_instruct1'\n",
        "\n",
        "if config.task == 'ate':\n",
        "    t5_exp = T5Generator(model_checkpoint)\n",
        "    bos_instruction_id = instruct_handler.ate[indomain]\n",
        "    bos_instruction_ood = instruct_handler.ate[outdomain] if (ood_tr_data_path or ood_te_data_path) else ''\n",
        "    eos_instruction = instruct_handler.ate['eos_instruct']\n",
        "elif config.task == 'atsc':\n",
        "    t5_exp = T5Classifier(model_checkpoint)\n",
        "    bos_instruction_id = instruct_handler.atsc[indomain]\n",
        "    bos_instruction_ood = instruct_handler.atsc[outdomain] if (ood_tr_data_path or ood_te_data_path) else ''\n",
        "    delim_instruction = instruct_handler.atsc['delim_instruct']\n",
        "    eos_instruction = instruct_handler.atsc['eos_instruct']\n",
        "elif config.task == 'joint':\n",
        "    t5_exp = T5Generator(model_checkpoint)\n",
        "    bos_instruction_id = instruct_handler.joint[indomain]\n",
        "    bos_instruction_ood = instruct_handler.joint[outdomain] if (ood_tr_data_path or ood_te_data_path) else ''\n",
        "    eos_instruction = instruct_handler.joint['eos_instruct']\n",
        "\n",
        "if config.mode != 'cli':\n",
        "    loader = DatasetLoader(id_tr_df, id_te_df, ood_tr_df, ood_te_df, config.sample_size)\n",
        "\n",
        "    if config.task == 'ate':\n",
        "        if loader.train_df_id is not None: loader.train_df_id = loader.create_data_in_ate_format(loader.train_df_id, 'term', 'raw_text', 'aspectTerms', bos_instruction_id, eos_instruction)\n",
        "        if loader.test_df_id is not None: loader.test_df_id = loader.create_data_in_ate_format(loader.test_df_id, 'term', 'raw_text', 'aspectTerms', bos_instruction_id, eos_instruction)\n",
        "    elif config.task == 'atsc':\n",
        "        if loader.train_df_id is not None: loader.train_df_id = loader.create_data_in_atsc_format(loader.train_df_id, 'aspectTerms', 'term', 'raw_text', 'aspect', bos_instruction_id, delim_instruction, eos_instruction)\n",
        "        if loader.test_df_id is not None: loader.test_df_id = loader.create_data_in_atsc_format(loader.test_df_id, 'aspectTerms', 'term', 'raw_text', 'aspect', bos_instruction_id, delim_instruction, eos_instruction)\n",
        "\n",
        "    id_ds, id_tokenized_ds, ood_ds, ood_tokenized_ds = loader.set_data_for_training_semeval(t5_exp.tokenize_function_inputs)\n",
        "\n",
        "    if config.mode == 'train':\n",
        "        model_trainer = t5_exp.train(id_tokenized_ds, **training_args)\n",
        "        print('Model saved at: ', model_out_path)\n",
        "    elif config.mode == 'eval':\n",
        "        print('Model loaded from: ', model_checkpoint)\n",
        "        if id_tokenized_ds.get(\"test\") is not None:\n",
        "            id_te_pred_labels = t5_exp.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'test', batch_size=config.per_device_eval_batch_size, max_length = config.max_token_length)\n",
        "            id_te_df = pd.DataFrame(id_ds['test'])[['text', 'labels']]\n",
        "            id_te_df['pred_labels'] = id_te_pred_labels\n",
        "            id_te_df.to_csv(os.path.join(config.output_path, f'{config.experiment_name}_id_test.csv'), index=False)\n",
        "            print('*****Test Metrics*****')\n",
        "            precision, recall, f1, accuracy = t5_exp.get_metrics(id_te_df['labels'], id_te_pred_labels)\n",
        "            print('Precision: ', precision)\n",
        "            print('Recall: ', recall)\n",
        "            print('F1-Score: ', f1)\n",
        "            if config.task == 'atsc': print('Accuracy: ', accuracy)\n",
        "else:\n",
        "    print(\"CLI mode not fully implemented in this unified script.\")\n",
        "''')\n",
        "\n",
        "print(\"Configuration files created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5tZkynFXAuC",
        "outputId": "d1957736-14a0-4dd9-84f4-74f8940bafc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-22 13:52:45.828572: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766411565.864731     410 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766411565.874214     410 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766411565.898921     410 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766411565.898958     410 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766411565.898967     410 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766411565.898974     410 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-22 13:52:45.906016: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loaded data...\n",
            "tokenizer_config.json: 2.54kB [00:00, 14.2MB/s]\n",
            "tokenizer_config.json: 2.54kB [00:00, 14.7MB/s]\n",
            "spiece.model: 100% 792k/792k [00:01<00:00, 670kB/s]\n",
            "tokenizer.json: 2.42MB [00:00, 44.9MB/s]\n",
            "special_tokens_map.json: 2.20kB [00:00, 12.3MB/s]\n",
            "tokenizer_config.json: 2.54kB [00:00, 23.1MB/s]\n",
            "config.json: 1.40kB [00:00, 6.88MB/s]\n",
            "config.json: 1.40kB [00:00, 12.0MB/s]\n",
            "model.safetensors: 100% 990M/990M [00:06<00:00, 143MB/s]\n",
            "generation_config.json: 100% 147/147 [00:00<00:00, 801kB/s]\n",
            "Map: 100% 10284/10284 [00:06<00:00, 1669.20 examples/s]\n",
            "Map: 100% 1125/1125 [00:00<00:00, 1730.92 examples/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtr-hoanganh1124\u001b[0m (\u001b[33mtr-hoanganh1124-hanoi-university-of-science-and-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m setting up run 6ld1h0uu (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/instructabsa/wandb/run-20251222_135416-6ld1h0uu\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mconfused-moon-3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/huggingface/runs/6ld1h0uu\u001b[0m\n",
            "{'loss': 0.4146, 'grad_norm': 10.512430191040039, 'learning_rate': 1.552099533437014e-05, 'epoch': 0.39}\n",
            "{'loss': 0.2831, 'grad_norm': 4.98480749130249, 'learning_rate': 1.8769656125799206e-05, 'epoch': 0.78}\n",
            " 20% 1286/6430 [13:34<48:00,  1.79it/s]\n",
            "  0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/71 [00:00<00:17,  3.84it/s]\u001b[A\n",
            "  4% 3/71 [00:00<00:21,  3.17it/s]\u001b[A\n",
            "  6% 4/71 [00:01<00:24,  2.74it/s]\u001b[A\n",
            "  7% 5/71 [00:01<00:25,  2.61it/s]\u001b[A\n",
            "  8% 6/71 [00:02<00:26,  2.48it/s]\u001b[A\n",
            " 10% 7/71 [00:02<00:26,  2.42it/s]\u001b[A\n",
            " 11% 8/71 [00:03<00:26,  2.41it/s]\u001b[A\n",
            " 13% 9/71 [00:03<00:26,  2.38it/s]\u001b[A\n",
            " 14% 10/71 [00:03<00:25,  2.42it/s]\u001b[A\n",
            " 15% 11/71 [00:04<00:25,  2.40it/s]\u001b[A\n",
            " 17% 12/71 [00:04<00:24,  2.42it/s]\u001b[A\n",
            " 18% 13/71 [00:05<00:23,  2.43it/s]\u001b[A\n",
            " 20% 14/71 [00:05<00:23,  2.41it/s]\u001b[A\n",
            " 21% 15/71 [00:05<00:23,  2.43it/s]\u001b[A\n",
            " 23% 16/71 [00:06<00:22,  2.43it/s]\u001b[A\n",
            " 24% 17/71 [00:06<00:22,  2.42it/s]\u001b[A\n",
            " 25% 18/71 [00:07<00:22,  2.40it/s]\u001b[A\n",
            " 27% 19/71 [00:07<00:21,  2.41it/s]\u001b[A\n",
            " 28% 20/71 [00:08<00:20,  2.44it/s]\u001b[A\n",
            " 30% 21/71 [00:08<00:20,  2.47it/s]\u001b[A\n",
            " 31% 22/71 [00:08<00:19,  2.45it/s]\u001b[A\n",
            " 32% 23/71 [00:09<00:19,  2.43it/s]\u001b[A\n",
            " 34% 24/71 [00:09<00:19,  2.39it/s]\u001b[A\n",
            " 35% 25/71 [00:10<00:19,  2.36it/s]\u001b[A\n",
            " 37% 26/71 [00:10<00:18,  2.38it/s]\u001b[A\n",
            " 38% 27/71 [00:10<00:18,  2.39it/s]\u001b[A\n",
            " 39% 28/71 [00:11<00:18,  2.36it/s]\u001b[A\n",
            " 41% 29/71 [00:11<00:17,  2.36it/s]\u001b[A\n",
            " 42% 30/71 [00:12<00:17,  2.34it/s]\u001b[A\n",
            " 44% 31/71 [00:12<00:17,  2.33it/s]\u001b[A\n",
            " 45% 32/71 [00:13<00:16,  2.35it/s]\u001b[A\n",
            " 46% 33/71 [00:13<00:15,  2.38it/s]\u001b[A\n",
            " 48% 34/71 [00:13<00:15,  2.39it/s]\u001b[A\n",
            " 49% 35/71 [00:14<00:14,  2.41it/s]\u001b[A\n",
            " 51% 36/71 [00:14<00:14,  2.40it/s]\u001b[A\n",
            " 52% 37/71 [00:15<00:14,  2.41it/s]\u001b[A\n",
            " 54% 38/71 [00:15<00:13,  2.43it/s]\u001b[A\n",
            " 55% 39/71 [00:15<00:13,  2.44it/s]\u001b[A\n",
            " 56% 40/71 [00:16<00:12,  2.42it/s]\u001b[A\n",
            " 58% 41/71 [00:16<00:12,  2.41it/s]\u001b[A\n",
            " 59% 42/71 [00:17<00:12,  2.41it/s]\u001b[A\n",
            " 61% 43/71 [00:17<00:11,  2.39it/s]\u001b[A\n",
            " 62% 44/71 [00:18<00:11,  2.40it/s]\u001b[A\n",
            " 63% 45/71 [00:18<00:10,  2.42it/s]\u001b[A\n",
            " 65% 46/71 [00:18<00:10,  2.40it/s]\u001b[A\n",
            " 66% 47/71 [00:19<00:09,  2.41it/s]\u001b[A\n",
            " 68% 48/71 [00:19<00:09,  2.43it/s]\u001b[A\n",
            " 69% 49/71 [00:20<00:08,  2.45it/s]\u001b[A\n",
            " 70% 50/71 [00:20<00:08,  2.43it/s]\u001b[A\n",
            " 72% 51/71 [00:20<00:08,  2.41it/s]\u001b[A\n",
            " 73% 52/71 [00:21<00:07,  2.40it/s]\u001b[A\n",
            " 75% 53/71 [00:21<00:07,  2.37it/s]\u001b[A\n",
            " 76% 54/71 [00:22<00:07,  2.40it/s]\u001b[A\n",
            " 77% 55/71 [00:22<00:06,  2.43it/s]\u001b[A\n",
            " 79% 56/71 [00:23<00:06,  2.46it/s]\u001b[A\n",
            " 80% 57/71 [00:23<00:05,  2.45it/s]\u001b[A\n",
            " 82% 58/71 [00:23<00:05,  2.47it/s]\u001b[A\n",
            " 83% 59/71 [00:24<00:04,  2.45it/s]\u001b[A\n",
            " 85% 60/71 [00:24<00:04,  2.42it/s]\u001b[A\n",
            " 86% 61/71 [00:25<00:04,  2.42it/s]\u001b[A\n",
            " 87% 62/71 [00:25<00:03,  2.43it/s]\u001b[A\n",
            " 89% 63/71 [00:25<00:03,  2.41it/s]\u001b[A\n",
            " 90% 64/71 [00:26<00:02,  2.37it/s]\u001b[A\n",
            " 92% 65/71 [00:26<00:02,  2.35it/s]\u001b[A\n",
            " 93% 66/71 [00:27<00:02,  2.32it/s]\u001b[A\n",
            " 94% 67/71 [00:27<00:01,  2.32it/s]\u001b[A\n",
            " 96% 68/71 [00:28<00:01,  2.34it/s]\u001b[A\n",
            " 97% 69/71 [00:28<00:00,  2.33it/s]\u001b[A\n",
            " 99% 70/71 [00:28<00:00,  2.35it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.24544507265090942, 'eval_runtime': 29.4979, 'eval_samples_per_second': 38.138, 'eval_steps_per_second': 2.407, 'epoch': 1.0}\n",
            " 20% 1286/6430 [14:04<48:00,  1.79it/s]\n",
            "100% 71/71 [00:29<00:00,  2.63it/s]\u001b[A\n",
            "{'loss': 0.2331, 'grad_norm': 9.84149169921875, 'learning_rate': 1.7041645066528427e-05, 'epoch': 1.17}\n",
            "{'loss': 0.2195, 'grad_norm': 4.562065601348877, 'learning_rate': 1.5313634007257648e-05, 'epoch': 1.56}\n",
            "{'loss': 0.2021, 'grad_norm': 9.362481117248535, 'learning_rate': 1.3585622947986867e-05, 'epoch': 1.94}\n",
            " 40% 2572/6430 [28:24<35:51,  1.79it/s]\n",
            "  0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/71 [00:00<00:19,  3.58it/s]\u001b[A\n",
            "  4% 3/71 [00:00<00:22,  3.05it/s]\u001b[A\n",
            "  6% 4/71 [00:01<00:24,  2.70it/s]\u001b[A\n",
            "  7% 5/71 [00:01<00:25,  2.59it/s]\u001b[A\n",
            "  8% 6/71 [00:02<00:26,  2.49it/s]\u001b[A\n",
            " 10% 7/71 [00:02<00:26,  2.43it/s]\u001b[A\n",
            " 11% 8/71 [00:03<00:25,  2.43it/s]\u001b[A\n",
            " 13% 9/71 [00:03<00:25,  2.40it/s]\u001b[A\n",
            " 14% 10/71 [00:03<00:25,  2.43it/s]\u001b[A\n",
            " 15% 11/71 [00:04<00:24,  2.41it/s]\u001b[A\n",
            " 17% 12/71 [00:04<00:24,  2.43it/s]\u001b[A\n",
            " 18% 13/71 [00:05<00:23,  2.43it/s]\u001b[A\n",
            " 20% 14/71 [00:05<00:23,  2.41it/s]\u001b[A\n",
            " 21% 15/71 [00:05<00:22,  2.44it/s]\u001b[A\n",
            " 23% 16/71 [00:06<00:22,  2.44it/s]\u001b[A\n",
            " 24% 17/71 [00:06<00:22,  2.42it/s]\u001b[A\n",
            " 25% 18/71 [00:07<00:21,  2.41it/s]\u001b[A\n",
            " 27% 19/71 [00:07<00:21,  2.42it/s]\u001b[A\n",
            " 28% 20/71 [00:08<00:20,  2.45it/s]\u001b[A\n",
            " 30% 21/71 [00:08<00:20,  2.47it/s]\u001b[A\n",
            " 31% 22/71 [00:08<00:19,  2.46it/s]\u001b[A\n",
            " 32% 23/71 [00:09<00:19,  2.43it/s]\u001b[A\n",
            " 34% 24/71 [00:09<00:19,  2.40it/s]\u001b[A\n",
            " 35% 25/71 [00:10<00:19,  2.37it/s]\u001b[A\n",
            " 37% 26/71 [00:10<00:18,  2.38it/s]\u001b[A\n",
            " 38% 27/71 [00:10<00:18,  2.38it/s]\u001b[A\n",
            " 39% 28/71 [00:11<00:18,  2.34it/s]\u001b[A\n",
            " 41% 29/71 [00:11<00:17,  2.35it/s]\u001b[A\n",
            " 42% 30/71 [00:12<00:17,  2.33it/s]\u001b[A\n",
            " 44% 31/71 [00:12<00:17,  2.33it/s]\u001b[A\n",
            " 45% 32/71 [00:13<00:16,  2.35it/s]\u001b[A\n",
            " 46% 33/71 [00:13<00:16,  2.37it/s]\u001b[A\n",
            " 48% 34/71 [00:13<00:15,  2.38it/s]\u001b[A\n",
            " 49% 35/71 [00:14<00:15,  2.40it/s]\u001b[A\n",
            " 51% 36/71 [00:14<00:14,  2.40it/s]\u001b[A\n",
            " 52% 37/71 [00:15<00:14,  2.42it/s]\u001b[A\n",
            " 54% 38/71 [00:15<00:13,  2.44it/s]\u001b[A\n",
            " 55% 39/71 [00:15<00:13,  2.45it/s]\u001b[A\n",
            " 56% 40/71 [00:16<00:12,  2.44it/s]\u001b[A\n",
            " 58% 41/71 [00:16<00:12,  2.43it/s]\u001b[A\n",
            " 59% 42/71 [00:17<00:11,  2.42it/s]\u001b[A\n",
            " 61% 43/71 [00:17<00:11,  2.39it/s]\u001b[A\n",
            " 62% 44/71 [00:18<00:11,  2.40it/s]\u001b[A\n",
            " 63% 45/71 [00:18<00:10,  2.41it/s]\u001b[A\n",
            " 65% 46/71 [00:18<00:10,  2.40it/s]\u001b[A\n",
            " 66% 47/71 [00:19<00:09,  2.41it/s]\u001b[A\n",
            " 68% 48/71 [00:19<00:09,  2.42it/s]\u001b[A\n",
            " 69% 49/71 [00:20<00:08,  2.45it/s]\u001b[A\n",
            " 70% 50/71 [00:20<00:08,  2.43it/s]\u001b[A\n",
            " 72% 51/71 [00:20<00:08,  2.41it/s]\u001b[A\n",
            " 73% 52/71 [00:21<00:07,  2.40it/s]\u001b[A\n",
            " 75% 53/71 [00:21<00:07,  2.37it/s]\u001b[A\n",
            " 76% 54/71 [00:22<00:07,  2.39it/s]\u001b[A\n",
            " 77% 55/71 [00:22<00:06,  2.43it/s]\u001b[A\n",
            " 79% 56/71 [00:23<00:06,  2.45it/s]\u001b[A\n",
            " 80% 57/71 [00:23<00:05,  2.45it/s]\u001b[A\n",
            " 82% 58/71 [00:23<00:05,  2.47it/s]\u001b[A\n",
            " 83% 59/71 [00:24<00:04,  2.45it/s]\u001b[A\n",
            " 85% 60/71 [00:24<00:04,  2.42it/s]\u001b[A\n",
            " 86% 61/71 [00:25<00:04,  2.41it/s]\u001b[A\n",
            " 87% 62/71 [00:25<00:03,  2.42it/s]\u001b[A\n",
            " 89% 63/71 [00:25<00:03,  2.38it/s]\u001b[A\n",
            " 90% 64/71 [00:26<00:02,  2.35it/s]\u001b[A\n",
            " 92% 65/71 [00:26<00:02,  2.33it/s]\u001b[A\n",
            " 93% 66/71 [00:27<00:02,  2.32it/s]\u001b[A\n",
            " 94% 67/71 [00:27<00:01,  2.33it/s]\u001b[A\n",
            " 96% 68/71 [00:28<00:01,  2.35it/s]\u001b[A\n",
            " 97% 69/71 [00:28<00:00,  2.34it/s]\u001b[A\n",
            " 99% 70/71 [00:28<00:00,  2.36it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.21370795369148254, 'eval_runtime': 29.5075, 'eval_samples_per_second': 38.126, 'eval_steps_per_second': 2.406, 'epoch': 2.0}\n",
            " 40% 2572/6430 [28:53<35:51,  1.79it/s]\n",
            "100% 71/71 [00:29<00:00,  2.64it/s]\u001b[A\n",
            "{'loss': 0.1835, 'grad_norm': 7.244100570678711, 'learning_rate': 1.1857611888716089e-05, 'epoch': 2.33}\n",
            "{'loss': 0.1798, 'grad_norm': 2.5941414833068848, 'learning_rate': 1.012960082944531e-05, 'epoch': 2.72}\n",
            " 60% 3858/6430 [43:21<23:52,  1.80it/s]\n",
            "  0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/71 [00:00<00:19,  3.63it/s]\u001b[A\n",
            "  4% 3/71 [00:00<00:22,  3.08it/s]\u001b[A\n",
            "  6% 4/71 [00:01<00:24,  2.71it/s]\u001b[A\n",
            "  7% 5/71 [00:01<00:25,  2.59it/s]\u001b[A\n",
            "  8% 6/71 [00:02<00:26,  2.48it/s]\u001b[A\n",
            " 10% 7/71 [00:02<00:26,  2.43it/s]\u001b[A\n",
            " 11% 8/71 [00:03<00:26,  2.41it/s]\u001b[A\n",
            " 13% 9/71 [00:03<00:26,  2.38it/s]\u001b[A\n",
            " 14% 10/71 [00:03<00:25,  2.42it/s]\u001b[A\n",
            " 15% 11/71 [00:04<00:24,  2.40it/s]\u001b[A\n",
            " 17% 12/71 [00:04<00:24,  2.42it/s]\u001b[A\n",
            " 18% 13/71 [00:05<00:23,  2.42it/s]\u001b[A\n",
            " 20% 14/71 [00:05<00:23,  2.40it/s]\u001b[A\n",
            " 21% 15/71 [00:05<00:23,  2.42it/s]\u001b[A\n",
            " 23% 16/71 [00:06<00:22,  2.42it/s]\u001b[A\n",
            " 24% 17/71 [00:06<00:22,  2.40it/s]\u001b[A\n",
            " 25% 18/71 [00:07<00:22,  2.38it/s]\u001b[A\n",
            " 27% 19/71 [00:07<00:21,  2.40it/s]\u001b[A\n",
            " 28% 20/71 [00:08<00:21,  2.42it/s]\u001b[A\n",
            " 30% 21/71 [00:08<00:20,  2.44it/s]\u001b[A\n",
            " 31% 22/71 [00:08<00:20,  2.44it/s]\u001b[A\n",
            " 32% 23/71 [00:09<00:19,  2.41it/s]\u001b[A\n",
            " 34% 24/71 [00:09<00:19,  2.38it/s]\u001b[A\n",
            " 35% 25/71 [00:10<00:19,  2.36it/s]\u001b[A\n",
            " 37% 26/71 [00:10<00:18,  2.38it/s]\u001b[A\n",
            " 38% 27/71 [00:11<00:18,  2.38it/s]\u001b[A\n",
            " 39% 28/71 [00:11<00:18,  2.35it/s]\u001b[A\n",
            " 41% 29/71 [00:11<00:17,  2.36it/s]\u001b[A\n",
            " 42% 30/71 [00:12<00:17,  2.34it/s]\u001b[A\n",
            " 44% 31/71 [00:12<00:17,  2.33it/s]\u001b[A\n",
            " 45% 32/71 [00:13<00:16,  2.35it/s]\u001b[A\n",
            " 46% 33/71 [00:13<00:16,  2.37it/s]\u001b[A\n",
            " 48% 34/71 [00:13<00:15,  2.40it/s]\u001b[A\n",
            " 49% 35/71 [00:14<00:14,  2.41it/s]\u001b[A\n",
            " 51% 36/71 [00:14<00:14,  2.40it/s]\u001b[A\n",
            " 52% 37/71 [00:15<00:14,  2.41it/s]\u001b[A\n",
            " 54% 38/71 [00:15<00:13,  2.43it/s]\u001b[A\n",
            " 55% 39/71 [00:16<00:13,  2.46it/s]\u001b[A\n",
            " 56% 40/71 [00:16<00:12,  2.43it/s]\u001b[A\n",
            " 58% 41/71 [00:16<00:12,  2.43it/s]\u001b[A\n",
            " 59% 42/71 [00:17<00:11,  2.43it/s]\u001b[A\n",
            " 61% 43/71 [00:17<00:11,  2.39it/s]\u001b[A\n",
            " 62% 44/71 [00:18<00:11,  2.40it/s]\u001b[A\n",
            " 63% 45/71 [00:18<00:10,  2.41it/s]\u001b[A\n",
            " 65% 46/71 [00:18<00:10,  2.40it/s]\u001b[A\n",
            " 66% 47/71 [00:19<00:09,  2.40it/s]\u001b[A\n",
            " 68% 48/71 [00:19<00:09,  2.41it/s]\u001b[A\n",
            " 69% 49/71 [00:20<00:09,  2.43it/s]\u001b[A\n",
            " 70% 50/71 [00:20<00:08,  2.40it/s]\u001b[A\n",
            " 72% 51/71 [00:21<00:08,  2.38it/s]\u001b[A\n",
            " 73% 52/71 [00:21<00:08,  2.37it/s]\u001b[A\n",
            " 75% 53/71 [00:21<00:07,  2.35it/s]\u001b[A\n",
            " 76% 54/71 [00:22<00:07,  2.38it/s]\u001b[A\n",
            " 77% 55/71 [00:22<00:06,  2.42it/s]\u001b[A\n",
            " 79% 56/71 [00:23<00:06,  2.45it/s]\u001b[A\n",
            " 80% 57/71 [00:23<00:05,  2.45it/s]\u001b[A\n",
            " 82% 58/71 [00:23<00:05,  2.47it/s]\u001b[A\n",
            " 83% 59/71 [00:24<00:04,  2.45it/s]\u001b[A\n",
            " 85% 60/71 [00:24<00:04,  2.42it/s]\u001b[A\n",
            " 86% 61/71 [00:25<00:04,  2.42it/s]\u001b[A\n",
            " 87% 62/71 [00:25<00:03,  2.43it/s]\u001b[A\n",
            " 89% 63/71 [00:25<00:03,  2.41it/s]\u001b[A\n",
            " 90% 64/71 [00:26<00:02,  2.37it/s]\u001b[A\n",
            " 92% 65/71 [00:26<00:02,  2.36it/s]\u001b[A\n",
            " 93% 66/71 [00:27<00:02,  2.33it/s]\u001b[A\n",
            " 94% 67/71 [00:27<00:01,  2.33it/s]\u001b[A\n",
            " 96% 68/71 [00:28<00:01,  2.35it/s]\u001b[A\n",
            " 97% 69/71 [00:28<00:00,  2.34it/s]\u001b[A\n",
            " 99% 70/71 [00:28<00:00,  2.36it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.22606463730335236, 'eval_runtime': 29.5508, 'eval_samples_per_second': 38.07, 'eval_steps_per_second': 2.403, 'epoch': 3.0}\n",
            " 60% 3858/6430 [43:51<23:52,  1.80it/s]\n",
            "100% 71/71 [00:29<00:00,  2.64it/s]\u001b[A\n",
            "{'loss': 0.1778, 'grad_norm': 4.698773384094238, 'learning_rate': 8.40158977017453e-06, 'epoch': 3.11}\n",
            "{'loss': 0.1652, 'grad_norm': 0.23815090954303741, 'learning_rate': 6.673578710903751e-06, 'epoch': 3.5}\n",
            "{'loss': 0.1706, 'grad_norm': 3.0054101943969727, 'learning_rate': 4.945567651632971e-06, 'epoch': 3.89}\n",
            " 80% 5144/6430 [58:16<11:56,  1.80it/s]\n",
            "  0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/71 [00:00<00:18,  3.63it/s]\u001b[A\n",
            "  4% 3/71 [00:00<00:22,  3.08it/s]\u001b[A\n",
            "  6% 4/71 [00:01<00:24,  2.72it/s]\u001b[A\n",
            "  7% 5/71 [00:01<00:25,  2.61it/s]\u001b[A\n",
            "  8% 6/71 [00:02<00:26,  2.50it/s]\u001b[A\n",
            " 10% 7/71 [00:02<00:26,  2.44it/s]\u001b[A\n",
            " 11% 8/71 [00:03<00:25,  2.43it/s]\u001b[A\n",
            " 13% 9/71 [00:03<00:25,  2.39it/s]\u001b[A\n",
            " 14% 10/71 [00:03<00:25,  2.41it/s]\u001b[A\n",
            " 15% 11/71 [00:04<00:25,  2.39it/s]\u001b[A\n",
            " 17% 12/71 [00:04<00:24,  2.41it/s]\u001b[A\n",
            " 18% 13/71 [00:05<00:24,  2.41it/s]\u001b[A\n",
            " 20% 14/71 [00:05<00:23,  2.39it/s]\u001b[A\n",
            " 21% 15/71 [00:05<00:23,  2.42it/s]\u001b[A\n",
            " 23% 16/71 [00:06<00:22,  2.42it/s]\u001b[A\n",
            " 24% 17/71 [00:06<00:22,  2.41it/s]\u001b[A\n",
            " 25% 18/71 [00:07<00:22,  2.40it/s]\u001b[A\n",
            " 27% 19/71 [00:07<00:21,  2.41it/s]\u001b[A\n",
            " 28% 20/71 [00:08<00:20,  2.44it/s]\u001b[A\n",
            " 30% 21/71 [00:08<00:20,  2.47it/s]\u001b[A\n",
            " 31% 22/71 [00:08<00:19,  2.45it/s]\u001b[A\n",
            " 32% 23/71 [00:09<00:19,  2.42it/s]\u001b[A\n",
            " 34% 24/71 [00:09<00:19,  2.38it/s]\u001b[A\n",
            " 35% 25/71 [00:10<00:19,  2.37it/s]\u001b[A\n",
            " 37% 26/71 [00:10<00:18,  2.39it/s]\u001b[A\n",
            " 38% 27/71 [00:10<00:18,  2.38it/s]\u001b[A\n",
            " 39% 28/71 [00:11<00:18,  2.35it/s]\u001b[A\n",
            " 41% 29/71 [00:11<00:17,  2.36it/s]\u001b[A\n",
            " 42% 30/71 [00:12<00:17,  2.34it/s]\u001b[A\n",
            " 44% 31/71 [00:12<00:17,  2.34it/s]\u001b[A\n",
            " 45% 32/71 [00:13<00:16,  2.36it/s]\u001b[A\n",
            " 46% 33/71 [00:13<00:15,  2.38it/s]\u001b[A\n",
            " 48% 34/71 [00:13<00:15,  2.41it/s]\u001b[A\n",
            " 49% 35/71 [00:14<00:14,  2.42it/s]\u001b[A\n",
            " 51% 36/71 [00:14<00:14,  2.41it/s]\u001b[A\n",
            " 52% 37/71 [00:15<00:14,  2.42it/s]\u001b[A\n",
            " 54% 38/71 [00:15<00:13,  2.45it/s]\u001b[A\n",
            " 55% 39/71 [00:15<00:13,  2.46it/s]\u001b[A\n",
            " 56% 40/71 [00:16<00:12,  2.44it/s]\u001b[A\n",
            " 58% 41/71 [00:16<00:12,  2.43it/s]\u001b[A\n",
            " 59% 42/71 [00:17<00:11,  2.42it/s]\u001b[A\n",
            " 61% 43/71 [00:17<00:11,  2.39it/s]\u001b[A\n",
            " 62% 44/71 [00:18<00:11,  2.40it/s]\u001b[A\n",
            " 63% 45/71 [00:18<00:10,  2.39it/s]\u001b[A\n",
            " 65% 46/71 [00:18<00:10,  2.39it/s]\u001b[A\n",
            " 66% 47/71 [00:19<00:09,  2.40it/s]\u001b[A\n",
            " 68% 48/71 [00:19<00:09,  2.42it/s]\u001b[A\n",
            " 69% 49/71 [00:20<00:08,  2.45it/s]\u001b[A\n",
            " 70% 50/71 [00:20<00:08,  2.42it/s]\u001b[A\n",
            " 72% 51/71 [00:20<00:08,  2.41it/s]\u001b[A\n",
            " 73% 52/71 [00:21<00:07,  2.40it/s]\u001b[A\n",
            " 75% 53/71 [00:21<00:07,  2.37it/s]\u001b[A\n",
            " 76% 54/71 [00:22<00:07,  2.40it/s]\u001b[A\n",
            " 77% 55/71 [00:22<00:06,  2.43it/s]\u001b[A\n",
            " 79% 56/71 [00:23<00:06,  2.46it/s]\u001b[A\n",
            " 80% 57/71 [00:23<00:05,  2.46it/s]\u001b[A\n",
            " 82% 58/71 [00:23<00:05,  2.48it/s]\u001b[A\n",
            " 83% 59/71 [00:24<00:04,  2.46it/s]\u001b[A\n",
            " 85% 60/71 [00:24<00:04,  2.43it/s]\u001b[A\n",
            " 86% 61/71 [00:25<00:04,  2.43it/s]\u001b[A\n",
            " 87% 62/71 [00:25<00:03,  2.44it/s]\u001b[A\n",
            " 89% 63/71 [00:25<00:03,  2.42it/s]\u001b[A\n",
            " 90% 64/71 [00:26<00:02,  2.38it/s]\u001b[A\n",
            " 92% 65/71 [00:26<00:02,  2.36it/s]\u001b[A\n",
            " 93% 66/71 [00:27<00:02,  2.35it/s]\u001b[A\n",
            " 94% 67/71 [00:27<00:01,  2.36it/s]\u001b[A\n",
            " 96% 68/71 [00:28<00:01,  2.38it/s]\u001b[A\n",
            " 97% 69/71 [00:28<00:00,  2.37it/s]\u001b[A\n",
            " 99% 70/71 [00:28<00:00,  2.39it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.2151477187871933, 'eval_runtime': 29.4395, 'eval_samples_per_second': 38.214, 'eval_steps_per_second': 2.412, 'epoch': 4.0}\n",
            " 80% 5144/6430 [58:45<11:56,  1.80it/s]\n",
            "100% 71/71 [00:29<00:00,  2.67it/s]\u001b[A\n",
            "{'loss': 0.1565, 'grad_norm': 5.182006359100342, 'learning_rate': 3.2175565923621917e-06, 'epoch': 4.28}\n",
            "{'loss': 0.1503, 'grad_norm': 7.646539211273193, 'learning_rate': 1.4895455330914118e-06, 'epoch': 4.67}\n",
            "100% 6430/6430 [1:14:04<00:00,  1.79it/s]\n",
            "  0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/71 [00:00<00:19,  3.59it/s]\u001b[A\n",
            "  4% 3/71 [00:00<00:22,  3.04it/s]\u001b[A\n",
            "  6% 4/71 [00:01<00:24,  2.69it/s]\u001b[A\n",
            "  7% 5/71 [00:01<00:25,  2.57it/s]\u001b[A\n",
            "  8% 6/71 [00:02<00:26,  2.48it/s]\u001b[A\n",
            " 10% 7/71 [00:02<00:26,  2.43it/s]\u001b[A\n",
            " 11% 8/71 [00:03<00:26,  2.41it/s]\u001b[A\n",
            " 13% 9/71 [00:03<00:25,  2.39it/s]\u001b[A\n",
            " 14% 10/71 [00:03<00:25,  2.42it/s]\u001b[A\n",
            " 15% 11/71 [00:04<00:24,  2.41it/s]\u001b[A\n",
            " 17% 12/71 [00:04<00:24,  2.43it/s]\u001b[A\n",
            " 18% 13/71 [00:05<00:23,  2.43it/s]\u001b[A\n",
            " 20% 14/71 [00:05<00:23,  2.41it/s]\u001b[A\n",
            " 21% 15/71 [00:05<00:22,  2.44it/s]\u001b[A\n",
            " 23% 16/71 [00:06<00:22,  2.43it/s]\u001b[A\n",
            " 24% 17/71 [00:06<00:22,  2.42it/s]\u001b[A\n",
            " 25% 18/71 [00:07<00:22,  2.41it/s]\u001b[A\n",
            " 27% 19/71 [00:07<00:21,  2.42it/s]\u001b[A\n",
            " 28% 20/71 [00:08<00:20,  2.44it/s]\u001b[A\n",
            " 30% 21/71 [00:08<00:20,  2.47it/s]\u001b[A\n",
            " 31% 22/71 [00:08<00:19,  2.46it/s]\u001b[A\n",
            " 32% 23/71 [00:09<00:19,  2.42it/s]\u001b[A\n",
            " 34% 24/71 [00:09<00:19,  2.40it/s]\u001b[A\n",
            " 35% 25/71 [00:10<00:19,  2.37it/s]\u001b[A\n",
            " 37% 26/71 [00:10<00:18,  2.38it/s]\u001b[A\n",
            " 38% 27/71 [00:10<00:18,  2.39it/s]\u001b[A\n",
            " 39% 28/71 [00:11<00:18,  2.36it/s]\u001b[A\n",
            " 41% 29/71 [00:11<00:17,  2.37it/s]\u001b[A\n",
            " 42% 30/71 [00:12<00:17,  2.35it/s]\u001b[A\n",
            " 44% 31/71 [00:12<00:17,  2.34it/s]\u001b[A\n",
            " 45% 32/71 [00:13<00:16,  2.35it/s]\u001b[A\n",
            " 46% 33/71 [00:13<00:15,  2.38it/s]\u001b[A\n",
            " 48% 34/71 [00:13<00:15,  2.40it/s]\u001b[A\n",
            " 49% 35/71 [00:14<00:15,  2.40it/s]\u001b[A\n",
            " 51% 36/71 [00:14<00:14,  2.39it/s]\u001b[A\n",
            " 52% 37/71 [00:15<00:14,  2.41it/s]\u001b[A\n",
            " 54% 38/71 [00:15<00:13,  2.43it/s]\u001b[A\n",
            " 55% 39/71 [00:15<00:13,  2.45it/s]\u001b[A\n",
            " 56% 40/71 [00:16<00:12,  2.44it/s]\u001b[A\n",
            " 58% 41/71 [00:16<00:12,  2.43it/s]\u001b[A\n",
            " 59% 42/71 [00:17<00:11,  2.42it/s]\u001b[A\n",
            " 61% 43/71 [00:17<00:11,  2.40it/s]\u001b[A\n",
            " 62% 44/71 [00:18<00:11,  2.40it/s]\u001b[A\n",
            " 63% 45/71 [00:18<00:10,  2.41it/s]\u001b[A\n",
            " 65% 46/71 [00:18<00:10,  2.40it/s]\u001b[A\n",
            " 66% 47/71 [00:19<00:09,  2.41it/s]\u001b[A\n",
            " 68% 48/71 [00:19<00:09,  2.43it/s]\u001b[A\n",
            " 69% 49/71 [00:20<00:08,  2.45it/s]\u001b[A\n",
            " 70% 50/71 [00:20<00:08,  2.43it/s]\u001b[A\n",
            " 72% 51/71 [00:20<00:08,  2.41it/s]\u001b[A\n",
            " 73% 52/71 [00:21<00:07,  2.40it/s]\u001b[A\n",
            " 75% 53/71 [00:21<00:07,  2.37it/s]\u001b[A\n",
            " 76% 54/71 [00:22<00:07,  2.40it/s]\u001b[A\n",
            " 77% 55/71 [00:22<00:06,  2.43it/s]\u001b[A\n",
            " 79% 56/71 [00:23<00:06,  2.45it/s]\u001b[A\n",
            " 80% 57/71 [00:23<00:05,  2.46it/s]\u001b[A\n",
            " 82% 58/71 [00:23<00:05,  2.48it/s]\u001b[A\n",
            " 83% 59/71 [00:24<00:04,  2.46it/s]\u001b[A\n",
            " 85% 60/71 [00:24<00:04,  2.43it/s]\u001b[A\n",
            " 86% 61/71 [00:25<00:04,  2.42it/s]\u001b[A\n",
            " 87% 62/71 [00:25<00:03,  2.43it/s]\u001b[A\n",
            " 89% 63/71 [00:25<00:03,  2.41it/s]\u001b[A\n",
            " 90% 64/71 [00:26<00:02,  2.36it/s]\u001b[A\n",
            " 92% 65/71 [00:26<00:02,  2.34it/s]\u001b[A\n",
            " 93% 66/71 [00:27<00:02,  2.31it/s]\u001b[A\n",
            " 94% 67/71 [00:27<00:01,  2.32it/s]\u001b[A\n",
            " 96% 68/71 [00:28<00:01,  2.34it/s]\u001b[A\n",
            " 97% 69/71 [00:28<00:00,  2.34it/s]\u001b[A\n",
            " 99% 70/71 [00:28<00:00,  2.35it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.23076358437538147, 'eval_runtime': 29.4966, 'eval_samples_per_second': 38.14, 'eval_steps_per_second': 2.407, 'epoch': 5.0}\n",
            "100% 6430/6430 [1:14:34<00:00,  1.79it/s]\n",
            "100% 71/71 [00:29<00:00,  2.64it/s]\u001b[A\n",
            "{'train_runtime': 4549.1829, 'train_samples_per_second': 11.303, 'train_steps_per_second': 1.413, 'train_loss': 0.20729730466661705, 'epoch': 5.0}\n",
            "100% 6430/6430 [1:15:02<00:00,  1.43it/s]\n",
            "Model saved at:  sentfin_model_output/atsc/googleflan-t5-base-run1\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mconfused-moon-3\u001b[0m at: \u001b[34m\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251222_135416-6ld1h0uu/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Run Training\n",
        "!python run_model.py \\\n",
        "    -task atsc \\\n",
        "    -mode train \\\n",
        "    -id_tr_data_path \"train_internal.csv\" \\\n",
        "    -id_te_data_path \"val_internal.csv\" \\\n",
        "    -model_checkpoint \"google/flan-t5-base\" \\\n",
        "    -num_train_epochs 5 \\\n",
        "    -per_device_train_batch_size 8 \\\n",
        "    -learning_rate 2e-5 \\\n",
        "    -output_dir \"sentfin_model_output\" \\\n",
        "    -experiment_name \"run1\" \\\n",
        "    -evaluation_strategy \"epoch\" \\\n",
        "    -save_strategy \"epoch\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRnU7LVSXAkV",
        "outputId": "84d6e38a-b963-41a9-d051-ac1e5466b823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "updating: sentfin_model_output/ (stored 0%)\n",
            "updating: sentfin_model_output/atsc/ (stored 0%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/ (stored 0%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/special_tokens_map.json (deflated 85%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/tokenizer_config.json (deflated 95%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-6430/ (stored 0%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-6430/special_tokens_map.json (deflated 85%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-6430/tokenizer_config.json (deflated 95%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-6430/training_args.bin (deflated 53%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-6430/config.json (deflated 62%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-6430/scheduler.pt (deflated 61%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-6430/spiece.model (deflated 48%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-6430/optimizer.pt (deflated 15%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-6430/trainer_state.json (deflated 71%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-6430/model.safetensors (deflated 7%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-6430/rng_state.pth (deflated 26%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-6430/tokenizer.json (deflated 74%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-6430/generation_config.json (deflated 27%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/training_args.bin (deflated 53%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/config.json (deflated 62%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-1286/ (stored 0%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-1286/special_tokens_map.json (deflated 85%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-1286/tokenizer_config.json (deflated 95%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-1286/training_args.bin (deflated 53%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-1286/config.json (deflated 62%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-1286/scheduler.pt (deflated 61%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-1286/spiece.model (deflated 48%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-1286/optimizer.pt (deflated 15%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-1286/trainer_state.json (deflated 58%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-1286/model.safetensors (deflated 7%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-1286/rng_state.pth (deflated 26%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-1286/tokenizer.json (deflated 74%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-1286/generation_config.json (deflated 27%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/spiece.model (deflated 48%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-3858/ (stored 0%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-3858/special_tokens_map.json (deflated 85%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-3858/tokenizer_config.json (deflated 95%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-3858/training_args.bin (deflated 53%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-3858/config.json (deflated 62%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-3858/scheduler.pt (deflated 61%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-3858/spiece.model (deflated 48%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-3858/optimizer.pt (deflated 15%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-3858/trainer_state.json (deflated 68%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-3858/model.safetensors (deflated 7%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-3858/rng_state.pth (deflated 26%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-3858/tokenizer.json (deflated 74%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-3858/generation_config.json (deflated 27%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/runs/ (stored 0%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/runs/Dec22_13-53-32_2deada21b7bb/ (stored 0%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/runs/Dec22_13-53-32_2deada21b7bb/events.out.tfevents.1766411615.2deada21b7bb.410.0 (deflated 63%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-2572/ (stored 0%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-2572/special_tokens_map.json (deflated 85%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-2572/tokenizer_config.json (deflated 95%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-2572/training_args.bin (deflated 53%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-2572/config.json (deflated 62%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-2572/scheduler.pt (deflated 61%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-2572/spiece.model (deflated 48%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-2572/optimizer.pt (deflated 15%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-2572/trainer_state.json (deflated 65%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-2572/model.safetensors (deflated 7%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-2572/rng_state.pth (deflated 26%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-2572/tokenizer.json (deflated 74%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-2572/generation_config.json (deflated 27%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-5144/ (stored 0%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-5144/special_tokens_map.json (deflated 85%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-5144/tokenizer_config.json (deflated 95%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-5144/training_args.bin (deflated 53%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-5144/config.json (deflated 62%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-5144/scheduler.pt (deflated 61%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-5144/spiece.model (deflated 48%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-5144/optimizer.pt (deflated 15%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-5144/trainer_state.json (deflated 70%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-5144/model.safetensors (deflated 7%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-5144/rng_state.pth (deflated 26%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-5144/tokenizer.json (deflated 74%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/checkpoint-5144/generation_config.json (deflated 27%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/model.safetensors (deflated 7%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/tokenizer.json (deflated 74%)\n",
            "updating: sentfin_model_output/atsc/googleflan-t5-base-run1/generation_config.json (deflated 27%)\n",
            "Mounted at /content/drive\n",
            "Copying my_final_model.zip to Google Drive...\n",
            "Success! Model saved to: /content/drive/MyDrive/my_final_model.zip\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Save Model to Drive\n",
        "!zip -r my_final_model.zip sentfin_model_output/\n",
        "\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define destination\n",
        "destination_folder = '/content/drive/MyDrive/'\n",
        "source_file = 'my_final_model.zip'\n",
        "\n",
        "if os.path.exists(source_file):\n",
        "    print(f\"Copying {source_file} to Google Drive...\")\n",
        "    shutil.copy(source_file, destination_folder)\n",
        "    print(f\"Success! Model saved to: {destination_folder}{source_file}\")\n",
        "else:\n",
        "    print(\"Error: my_final_model.zip not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZLDTTCpXAbX",
        "outputId": "19ff5c8e-8f2b-4f12-a565-b28c996dc3bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference patches applied (switched to max_new_tokens for generation).\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Apply Inference Patches (Fixing utils.py and run_model.py)\n",
        "\n",
        "# 1. Update run_model.py to handle evaluation_strategy naming if needed\n",
        "# (Actually, the version written in Cell 2 already handles this via the if-check,\n",
        "# but we will ensure the variable naming aligns with what Config expects).\n",
        "# We primarily need to update utils.py for the max_new_tokens fix.\n",
        "\n",
        "updated_utils_code = \"\"\"\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "from transformers import (\n",
        "    DataCollatorForSeq2Seq, AutoTokenizer, AutoModelForSeq2SeqLM,\n",
        "    Seq2SeqTrainingArguments, Trainer, Seq2SeqTrainer\n",
        ")\n",
        "\n",
        "class T5Generator:\n",
        "    def __init__(self, model_checkpoint):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
        "        self.data_collator = DataCollatorForSeq2Seq(self.tokenizer)\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "\n",
        "    def tokenize_function_inputs(self, sample):\n",
        "        model_inputs = self.tokenizer(sample['text'], max_length=512, truncation=True)\n",
        "        labels = self.tokenizer(sample[\"labels\"], max_length=64, truncation=True)\n",
        "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "        return model_inputs\n",
        "\n",
        "    def train(self, tokenized_datasets, **kwargs):\n",
        "        args = Seq2SeqTrainingArguments(**kwargs)\n",
        "        eval_ds = tokenized_datasets.get(\"validation\")\n",
        "        if eval_ds is None: eval_ds = tokenized_datasets.get(\"test\")\n",
        "        trainer = Seq2SeqTrainer(\n",
        "            self.model, args, train_dataset=tokenized_datasets[\"train\"],\n",
        "            eval_dataset=eval_ds, tokenizer=self.tokenizer, data_collator=self.data_collator,\n",
        "        )\n",
        "        torch.cuda.empty_cache()\n",
        "        trainer.train()\n",
        "        trainer.save_model()\n",
        "        return trainer\n",
        "\n",
        "    def get_labels(self, tokenized_dataset, batch_size=4, max_length=128, sample_set='train'):\n",
        "        def collate_fn(batch):\n",
        "            input_ids = [torch.tensor(example['input_ids']) for example in batch]\n",
        "            input_ids = pad_sequence(input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
        "            return input_ids\n",
        "        dataloader = DataLoader(tokenized_dataset[sample_set], batch_size=batch_size, collate_fn=collate_fn)\n",
        "        predicted_output = []\n",
        "        self.model.to(self.device)\n",
        "        for batch in tqdm(dataloader):\n",
        "            batch = batch.to(self.device)\n",
        "            # FIXED: max_new_tokens\n",
        "            output_ids = self.model.generate(batch, max_new_tokens=max_length)\n",
        "            output_texts = self.tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "            for output_text in output_texts: predicted_output.append(output_text)\n",
        "        return predicted_output\n",
        "\n",
        "    def get_metrics(self, y_true, y_pred, is_triplet_extraction=False):\n",
        "        return precision_score(y_true, y_pred, average='macro'), recall_score(y_true, y_pred, average='macro'), f1_score(y_true, y_pred, average='macro'), accuracy_score(y_true, y_pred)\n",
        "\n",
        "class T5Classifier:\n",
        "    def __init__(self, model_checkpoint):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, force_download=True)\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, force_download=True)\n",
        "        self.data_collator = DataCollatorForSeq2Seq(self.tokenizer)\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "\n",
        "    def tokenize_function_inputs(self, sample):\n",
        "        sample['input_ids'] = self.tokenizer(sample[\"text\"], max_length=512, truncation=True).input_ids\n",
        "        sample['labels'] = self.tokenizer(sample[\"labels\"], max_length=64, truncation=True).input_ids\n",
        "        return sample\n",
        "\n",
        "    def train(self, tokenized_datasets, **kwargs):\n",
        "        args = Seq2SeqTrainingArguments(**kwargs)\n",
        "        eval_ds = tokenized_datasets.get(\"validation\")\n",
        "        if eval_ds is None: eval_ds = tokenized_datasets.get(\"test\")\n",
        "        trainer = Trainer(\n",
        "            self.model, args, train_dataset=tokenized_datasets[\"train\"],\n",
        "            eval_dataset=eval_ds, tokenizer=self.tokenizer, data_collator=self.data_collator\n",
        "        )\n",
        "        torch.cuda.empty_cache()\n",
        "        trainer.train()\n",
        "        trainer.save_model()\n",
        "        return trainer\n",
        "\n",
        "    def get_labels(self, tokenized_dataset, batch_size=4, max_length=128, sample_set='train'):\n",
        "        def collate_fn(batch):\n",
        "            input_ids = [torch.tensor(example['input_ids']) for example in batch]\n",
        "            input_ids = pad_sequence(input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
        "            return input_ids\n",
        "        dataloader = DataLoader(tokenized_dataset[sample_set], batch_size=batch_size, collate_fn=collate_fn)\n",
        "        predicted_output = []\n",
        "        self.model.to(self.device)\n",
        "        for batch in tqdm(dataloader):\n",
        "            batch = batch.to(self.device)\n",
        "            # FIXED: max_new_tokens (This was the critical bug in the inference NB)\n",
        "            output_ids = self.model.generate(batch, max_new_tokens=max_length)\n",
        "            output_texts = self.tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "            for output_text in output_texts: predicted_output.append(output_text)\n",
        "        return predicted_output\n",
        "\n",
        "    def get_metrics(self, y_true, y_pred):\n",
        "        return precision_score(y_true, y_pred, average='macro'), recall_score(y_true, y_pred, average='macro'), \\\n",
        "            f1_score(y_true, y_pred, average='macro'), accuracy_score(y_true, y_pred)\n",
        "\"\"\"\n",
        "\n",
        "with open(\"InstructABSA/utils.py\", \"w\") as f:\n",
        "    f.write(updated_utils_code)\n",
        "\n",
        "print(\"Inference patches applied (switched to max_new_tokens for generation).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vKt9qRfXAB9",
        "outputId": "39527f0c-ba03-4f94-d4b9-cc7542776b74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-22 15:47:33.146820: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766418453.174633   30982 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766418453.181657   30982 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766418453.199789   30982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766418453.199819   30982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766418453.199826   30982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766418453.199829   30982 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-22 15:47:33.205060: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loaded data...\n",
            "Model loaded from:  sentfin_model_output/atsc/googleflan-t5-base-run1\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Run Evaluation\n",
        "!python run_model.py \\\n",
        "    -task atsc \\\n",
        "    -mode eval \\\n",
        "    -id_te_data_path \"test_internal.csv\" \\\n",
        "    -model_checkpoint \"sentfin_model_output/atsc/googleflan-t5-base-run1\" \\\n",
        "    -output_dir \"sentfin_model_output\" \\\n",
        "    -output_path \"sentfin_model_output\" \\\n",
        "    -experiment_name \"run1_eval\" \\\n",
        "    -per_device_eval_batch_size 16 \\\n",
        "    -max_token_length 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhDtlIh0BTLT",
        "outputId": "67bf6759-2fd5-4d6c-b5a5-4e186a064ee5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Unzipping /content/drive/MyDrive/my_final_model.zip to unzipped_model/...\n",
            "Unzipping complete!\n"
          ]
        }
      ],
      "source": [
        "#Cell 7\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive if not already mounted\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define the path to the zipped model in Google Drive\n",
        "gdrive_path = '/content/drive/MyDrive/my_final_model.zip'\n",
        "\n",
        "# Define the destination directory for unzipping\n",
        "unzip_destination = 'unzipped_model/'\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "os.makedirs(unzip_destination, exist_ok=True)\n",
        "\n",
        "# Unzip the file from Google Drive to the specified local directory\n",
        "if os.path.exists(gdrive_path):\n",
        "    print(f\"Unzipping {gdrive_path} to {unzip_destination}...\")\n",
        "    !unzip -q {gdrive_path} -d {unzip_destination}\n",
        "    print(\"Unzipping complete!\")\n",
        "else:\n",
        "    print(f\"Error: {gdrive_path} not found in Google Drive.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "ozH2JopXW_UZ",
        "outputId": "75927459-bf18-4f48-9e67-b2652490a74e"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3240134538.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Cell 7: Manual Inference Tool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sentfin_model_output/atsc/googleflan-t5-base-run1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_decoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoderDecoderConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mauto_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LazyAutoMapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m from .configuration_auto import (\n\u001b[1;32m     42\u001b[0m     \u001b[0mCONFIG_MAPPING_NAMES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mgeneration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_deepspeed_zero3_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsdp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_fsdp_managed_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasking_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_masks_for_generate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misin_mps_friendly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExtensionsTrie\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/masking_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_torch_greater_or_equal_than_2_6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace_wrapped_higher_order_op\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformGetItemToIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m from . import (\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0maot_compile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/aot_compile.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecompile_context\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPrecompileContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallbackTrigger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mObservedException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorifyScalarRestartAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdump_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/exc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcounters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/fx/experimental/symbolic_shapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m         assuming, Q, ask, register_handler, remove_handler, refine)\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpquo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mpexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_gcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/polys/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m ]\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m from .polytools import (Poly, PurePoly, poly_from_expr,\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mparallel_poly_from_expr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mLT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_gcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcdex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Cell 8: Manual Inference Tool\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "model_path = \"sentfin_model_output/atsc/googleflan-t5-base-run1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to('cuda')\n",
        "\n",
        "def predict_sentiment(text, aspect):\n",
        "    prompt = (\n",
        "        \"Definition: The output will be 'positive' if the sentiment of the identified \"\n",
        "        \"financial entity or aspect in the input is positive (good news, growth, profit). \"\n",
        "        \"If the sentiment is negative (loss, drop, risk), the answer will be 'negative'. \"\n",
        "        \"Otherwise, the output should be 'neutral'.\\n\"\n",
        "        \"Positive example 1- input: Profits for Apple surged. The aspect is Profits. output: positive\\n\"\n",
        "        \"Negative example 1- input: Tesla stock crashed. The aspect is stock. output: negative\\n\"\n",
        "        \"Now complete the following example-\\n\"\n",
        "        f\"input: {text} The aspect is {aspect}.\\noutput:\"\n",
        "    )\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
        "    # Using max_new_tokens here as well to align with the patch\n",
        "    outputs = model.generate(**inputs, max_new_tokens=10)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Try it out!\n",
        "text = \"China’s exports to U.S. extend double-digit declines, dropping 29% in November, despite trade truce\"\n",
        "aspect = \"China\"\n",
        "print(f\"Input: {text} | Aspect: {aspect}\")\n",
        "print(f\"Prediction: {predict_sentiment(text, aspect)}\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# New test case: term not in text\n",
        "text_implicit = \"The company reported unexpectedly low quarterly earnings, causing investor concern.\"\n",
        "aspect_implicit = \"stock price\"\n",
        "print(f\"Input: {text_implicit} | Aspect: {aspect_implicit}\")\n",
        "print(f\"Prediction: {predict_sentiment(text_implicit, aspect_implicit)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dokuUHdEztjx",
        "outputId": "7e0671d9-955e-4acc-8cce-2952ce9ea375"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"test\",\n  \"rows\": 2227,\n  \"fields\": [\n    {\n      \"column\": \"sentenceId\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2227,\n        \"samples\": [\n          \"375:1\",\n          \"2514:1\",\n          \"8247:1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2220,\n        \"samples\": [\n          \"Investor accounts at NSDL, CDSL cross 2 crore\",\n          \"Man Industries rallies 5% on Rs 500 crore orders win\",\n          \"Does Sesa Sterlite look attractive as SC lifts ban?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aspectTerms\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1393,\n        \"samples\": [\n          \"[{'term': 'Monsanto India', 'polarity': 'positive'}]\",\n          \"[{'term': 'Jaypee Group', 'polarity': 'positive'}, {'term': 'JSW Energy', 'polarity': 'neutral'}]\",\n          \"[{'term': 'Re', 'polarity': 'positive'}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aspectCategories\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"[{'category': 'none', 'polarity': 'none'}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "test"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c2c90d2a-3c95-4997-a305-34ea049fabe0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentenceId</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>aspectTerms</th>\n",
              "      <th>aspectCategories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0:1</td>\n",
              "      <td>SpiceJet to issue 6.4 crore warrants to promoters</td>\n",
              "      <td>[{'term': 'SpiceJet', 'polarity': 'neutral'}]</td>\n",
              "      <td>[{'category': 'none', 'polarity': 'none'}]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11:1</td>\n",
              "      <td>Wait and watch on Bharti Airtel: Vinay Khattar</td>\n",
              "      <td>[{'term': 'Bharti Airtel', 'polarity': 'neutra...</td>\n",
              "      <td>[{'category': 'none', 'polarity': 'none'}]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17:1</td>\n",
              "      <td>US stocks finish mixed amid more tech selling</td>\n",
              "      <td>[{'term': 'tech', 'polarity': 'negative'}, {'t...</td>\n",
              "      <td>[{'category': 'none', 'polarity': 'none'}]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21:1</td>\n",
              "      <td>Gur closes quiet on some support</td>\n",
              "      <td>[{'term': 'Gur', 'polarity': 'neutral'}]</td>\n",
              "      <td>[{'category': 'none', 'polarity': 'none'}]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22:1</td>\n",
              "      <td>Gur closes steady on low demand</td>\n",
              "      <td>[{'term': 'Gur', 'polarity': 'neutral'}]</td>\n",
              "      <td>[{'category': 'none', 'polarity': 'none'}]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2c90d2a-3c95-4997-a305-34ea049fabe0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c2c90d2a-3c95-4997-a305-34ea049fabe0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c2c90d2a-3c95-4997-a305-34ea049fabe0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8f3e73c4-b286-4008-b848-f37b5fbe6a37\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f3e73c4-b286-4008-b848-f37b5fbe6a37')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8f3e73c4-b286-4008-b848-f37b5fbe6a37 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  sentenceId                                           raw_text  \\\n",
              "0        0:1  SpiceJet to issue 6.4 crore warrants to promoters   \n",
              "1       11:1     Wait and watch on Bharti Airtel: Vinay Khattar   \n",
              "2       17:1      US stocks finish mixed amid more tech selling   \n",
              "3       21:1                   Gur closes quiet on some support   \n",
              "4       22:1                    Gur closes steady on low demand   \n",
              "\n",
              "                                         aspectTerms  \\\n",
              "0      [{'term': 'SpiceJet', 'polarity': 'neutral'}]   \n",
              "1  [{'term': 'Bharti Airtel', 'polarity': 'neutra...   \n",
              "2  [{'term': 'tech', 'polarity': 'negative'}, {'t...   \n",
              "3           [{'term': 'Gur', 'polarity': 'neutral'}]   \n",
              "4           [{'term': 'Gur', 'polarity': 'neutral'}]   \n",
              "\n",
              "                             aspectCategories  \n",
              "0  [{'category': 'none', 'polarity': 'none'}]  \n",
              "1  [{'category': 'none', 'polarity': 'none'}]  \n",
              "2  [{'category': 'none', 'polarity': 'none'}]  \n",
              "3  [{'category': 'none', 'polarity': 'none'}]  \n",
              "4  [{'category': 'none', 'polarity': 'none'}]  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = pd.read_csv(\"test_internal.csv\")\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "7acc8112adf84790a2fdf6d6d1836472",
            "b811b27229904ee7a459a874c3554a39",
            "806c0b063ad44722a1ec9bc0715d0779",
            "1aab79c5f6bc4a6abb73fbadb31c538d",
            "d7ee1c45ae364c89945dc48c566c671f",
            "4495b74345b24e2ebc4964f1ed7ccac4",
            "91e021c4c7274c688340601bcd7d9ba8",
            "e01ee529e1524423a5ce92cde6029d95",
            "00af62a843a1446e88cda36721b173cf",
            "1a7a88ce78704ea4be9ea298c4b69cc0",
            "912b82e321ed4baa834ab187454bd3b5"
          ]
        },
        "id": "3Ji7jL_unrKa",
        "outputId": "6e8f594c-c300-4fd4-8b01-874295d7e3ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/instructabsa/InstructABSA/data_prep.py:46: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  df['aspect'] = df[[on, 'record_idx']].apply(lambda x : (x[0][x[1]][key], x[0][x[1]]['polarity']) if len(x[0]) != 0 else ('',''), axis=1)\n",
            "/content/instructabsa/InstructABSA/data_prep.py:76: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  df['text'] = df[[text_col, aspect_col]].apply(lambda x: bos_instruction + x[0] + delim_instruction + x[1] + eos_instruction, axis=1)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7acc8112adf84790a2fdf6d6d1836472",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 750/750 [01:37<00:00,  7.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "***** Evaluation Metrics on Test Data *****\n",
            "Precision: 0.8945\n",
            "Recall: 0.8977\n",
            "F1-Score: 0.8958\n",
            "Accuracy: 0.8953\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Cell 10\n",
        "# Load the model manually (or use your existing pipeline)\n",
        "from InstructABSA.utils import T5Classifier\n",
        "from InstructABSA.data_prep import DatasetLoader\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "# 1. Load Model\n",
        "model_path = \"sentfin_model_output/atsc/googleflan-t5-base-run1\"\n",
        "t5_classifier = T5Classifier(model_path)\n",
        "\n",
        "# 2. Prepare Data (Example with Test Data)\n",
        "# Using the full test_internal.csv as requested\n",
        "original_test_df = pd.read_csv(\"test_internal.csv\")\n",
        "loader = DatasetLoader(None, original_test_df, None, None)\n",
        "\n",
        "# Get Instruction prompts\n",
        "from instructions import InstructionsHandler\n",
        "ih = InstructionsHandler()\n",
        "bos_instruct = ih.atsc['bos_instruct2'] # Use the instruction set you prefer\n",
        "delim_instruct = ih.atsc['delim_instruct']\n",
        "eos_instruct = ih.atsc['eos_instruct']\n",
        "\n",
        "# Format Data\n",
        "# This call expands the DataFrame so that each row corresponds to one aspect term\n",
        "processed_data_for_prediction = loader.create_data_in_atsc_format(\n",
        "    loader.test_df_id, 'aspectTerms', 'term', 'raw_text', 'aspect',\n",
        "    bos_instruct, delim_instruct, eos_instruct\n",
        ")\n",
        "\n",
        "# Tokenize\n",
        "from datasets import Dataset\n",
        "hf_dataset = Dataset.from_pandas(processed_data_for_prediction)\n",
        "tokenized_dataset = hf_dataset.map(t5_classifier.tokenize_function_inputs, batched=True)\n",
        "wrapped_dataset = {\"test\": tokenized_dataset}\n",
        "\n",
        "# 3. Get predicted labels\n",
        "predicted_labels = t5_classifier.get_labels(\n",
        "    wrapped_dataset, sample_set=\"test\", max_length=10 # Max_length for sentiment output (e.g., 'positive')\n",
        ")\n",
        "\n",
        "# Calculate and Display Metrics\n",
        "y_true = processed_data_for_prediction['labels'].tolist()\n",
        "y_pred = predicted_labels\n",
        "\n",
        "precision, recall, f1, accuracy = t5_classifier.get_metrics(y_true, y_pred)\n",
        "\n",
        "print('\\n***** Evaluation Metrics on Test Data *****')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1-Score: {f1:.4f}')\n",
        "print(f'Accuracy: {accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yfj9jXe4Umw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eFM8_uqAcv1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00af62a843a1446e88cda36721b173cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a7a88ce78704ea4be9ea298c4b69cc0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aab79c5f6bc4a6abb73fbadb31c538d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a7a88ce78704ea4be9ea298c4b69cc0",
            "placeholder": "​",
            "style": "IPY_MODEL_912b82e321ed4baa834ab187454bd3b5",
            "value": " 3000/3000 [00:01&lt;00:00, 1626.92 examples/s]"
          }
        },
        "4495b74345b24e2ebc4964f1ed7ccac4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7acc8112adf84790a2fdf6d6d1836472": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b811b27229904ee7a459a874c3554a39",
              "IPY_MODEL_806c0b063ad44722a1ec9bc0715d0779",
              "IPY_MODEL_1aab79c5f6bc4a6abb73fbadb31c538d"
            ],
            "layout": "IPY_MODEL_d7ee1c45ae364c89945dc48c566c671f"
          }
        },
        "806c0b063ad44722a1ec9bc0715d0779": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e01ee529e1524423a5ce92cde6029d95",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00af62a843a1446e88cda36721b173cf",
            "value": 3000
          }
        },
        "912b82e321ed4baa834ab187454bd3b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91e021c4c7274c688340601bcd7d9ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b811b27229904ee7a459a874c3554a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4495b74345b24e2ebc4964f1ed7ccac4",
            "placeholder": "​",
            "style": "IPY_MODEL_91e021c4c7274c688340601bcd7d9ba8",
            "value": "Map: 100%"
          }
        },
        "d7ee1c45ae364c89945dc48c566c671f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e01ee529e1524423a5ce92cde6029d95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}